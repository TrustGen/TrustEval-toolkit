{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(parent_dir)\n",
    "from section.privacy.privacy_llm import pipeline\n",
    "base_dir = \"./test/privacy/\"\n",
    "\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "pipeline.pipeline(base_dir=base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(parent_dir)\n",
    "base_dir = \"./test/privacy/\"\n",
    "\n",
    "from responses import process_datafolder \n",
    "import shutil\n",
    "source_config = \"../section/privacy/privacy_llm/file_config.json\"\n",
    "target_config = os.path.join(base_dir,\"final\",\"file_config.json\")\n",
    "\n",
    "if os.path.exists(source_config):\n",
    "    shutil.copy2(source_config, target_config)\n",
    "    print(f\"Successfully copied file_config to {target_config}\")\n",
    "else:\n",
    "    print(\"Warning: Source file_config not found\")\n",
    "    \n",
    "data_folder  = os.path.join(base_dir,\"final\")\n",
    "# model_list = [\n",
    "#     'gpt-4o', 'gpt-4o-mini', 'gpt-3.5-turbo',\n",
    "#     'claude-3.5-sonnet', 'claude-3-haiku',\n",
    "#     'gemini-1.5-pro', 'gemini-1.5-flash', 'gemma-2-27B',\n",
    "#     'llama-3.1-70B', 'llama-3.1-8B',\n",
    "#     'glm-4-plus', 'qwen-2.5-72B', \n",
    "#     'mistral-8x7B', 'mistral-8x22B',\n",
    "#     'yi-lightning', 'deepseek-chat']\n",
    "model_list = [\n",
    "    'gpt-4o']\n",
    "\n",
    "async def process_files_original():\n",
    "    request_types = ['llm',]\n",
    "    prompt_keys,result_keys = ['prompt'], ['responses']\n",
    "    for request_type, prompt_key,result_key in zip(request_types, prompt_keys, result_keys):\n",
    "        await process_datafolder(\n",
    "            data_folder, request_type=request_type, async_list=model_list, sync_list=[],\n",
    "            prompt_key=prompt_key, result_key=result_key,file_name_extension='_responses'\n",
    "        )\n",
    "    print(\"All files processed.\")\n",
    "await process_files_original()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation.judge import JudgeProcessor\n",
    "\n",
    "config_path = '../src/config/judge_prompt.yaml'\n",
    "async_judge_model = ['gpt-4o-mini']\n",
    "response_key = ['responses']\n",
    "judge_key = 'judge'\n",
    "judge_type='llm'\n",
    "model_list = [\n",
    "    'gpt-4o']\n",
    "processor = JudgeProcessor(\n",
    "    folder_path=data_folder,config_path=config_path, \n",
    "    async_judge_model=async_judge_model, \n",
    "    response_key=response_key, judge_key=judge_key,\n",
    "    target_async_model=model_list, target_sync_model=[],\n",
    "    response_extension='_responses',judge_extension='_judge',\n",
    "    judge_type=judge_type\n",
    ")\n",
    "\n",
    "await processor.process_files(max_concurrent_tasks=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
