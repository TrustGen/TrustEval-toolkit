{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truthfullness LLM\n",
    "### Metadata Curator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "base_dir = os.getcwd() + '/truthfulness_llm'\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and build the dataset_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trusteval import download_metadata\n",
    "\n",
    "download_metadata(\n",
    "    section='truthfulness_llm',\n",
    "    output_path=base_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trusteval.dimension.truthfulness.truthfulness_llm import dynamic_dataset_generator\n",
    "\n",
    "dynamic_dataset_generator(\n",
    "    base_dir=base_dir,\n",
    "    mode='dataset_pool'\n",
    ")\n",
    "dynamic_dataset_generator(\n",
    "    base_dir=base_dir,\n",
    "    mode='dynamic'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contexual Variator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trusteval import contextual_variator_cli\n",
    "\n",
    "contextual_variator_cli(\n",
    "    dataset_folder=base_dir + '/final'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: qa.json -> d:\\Paper\\TrustEval-toolkit\\examples/truthfulness_llm\\qa_enhanced_responses.json\n",
      "2024-12-31 15:40:46,601 [ERROR] Failed to load data from d:\\Paper\\TrustEval-toolkit\\examples/truthfulness_llm\\qa_enhanced_responses.json: Expecting value: line 45860 column 23 (char 9516468)\n",
      "Processing file: qa_context.json -> d:\\Paper\\TrustEval-toolkit\\examples/truthfulness_llm\\qa_context_enhanced_responses.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing items: 100%|██████████| 200/200 [00:09<00:00, 21.66it/s]\n",
      "Processing files:  17%|█▋        | 2/12 [00:09<00:46,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: fc.json -> d:\\Paper\\TrustEval-toolkit\\examples/truthfulness_llm\\fc_enhanced_responses.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing items: 100%|██████████| 200/200 [00:12<00:00, 16.52it/s]\n",
      "Processing files:  25%|██▌       | 3/12 [00:21<01:10,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: persona.json -> d:\\Paper\\TrustEval-toolkit\\examples/truthfulness_llm\\persona_enhanced_responses.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing items: 100%|██████████| 100/100 [00:04<00:00, 23.86it/s]\n",
      "Processing files:  33%|███▎      | 4/12 [00:25<00:51,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: persona_base.json -> d:\\Paper\\TrustEval-toolkit\\examples/truthfulness_llm\\persona_base_responses.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing items: 100%|██████████| 100/100 [00:04<00:00, 24.43it/s]\n",
      "Processing files:  42%|████▏     | 5/12 [00:29<00:39,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: preconception.json -> d:\\Paper\\TrustEval-toolkit\\examples/truthfulness_llm\\preconception_enhanced_responses.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing items: 100%|██████████| 100/100 [00:03<00:00, 27.82it/s]\n",
      "Processing files:  50%|█████     | 6/12 [00:33<00:30,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: preconception_base.json -> d:\\Paper\\TrustEval-toolkit\\examples/truthfulness_llm\\preconception_base_responses.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing items: 100%|██████████| 100/100 [00:03<00:00, 28.60it/s]\n",
      "Processing files:  58%|█████▊    | 7/12 [00:37<00:22,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: self_doubt.json -> d:\\Paper\\TrustEval-toolkit\\examples/truthfulness_llm\\self_doubt_enhanced_responses.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing items: 100%|██████████| 100/100 [00:05<00:00, 19.28it/s]\n",
      "Processing files:  67%|██████▋   | 8/12 [00:42<00:19,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: trustllm_internal.json -> d:\\Paper\\TrustEval-toolkit\\examples/truthfulness_llm\\trustllm_internal_responses.json\n",
      "2024-12-31 15:41:29,178 [ERROR] Failed to load data from d:\\Paper\\TrustEval-toolkit\\examples/truthfulness_llm\\trustllm_internal_responses.json: Expecting value: line 109782 column 41 (char 12884303)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  75%|███████▌  | 9/12 [00:42<00:10,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: trustllm_external.json -> d:\\Paper\\TrustEval-toolkit\\examples/truthfulness_llm\\trustllm_external_responses.json\n",
      "2024-12-31 15:41:29,238 [ERROR] Failed to load data from d:\\Paper\\TrustEval-toolkit\\examples/truthfulness_llm\\trustllm_external_responses.json: Expecting property name enclosed in double quotes: line 76787 column 21 (char 8280213)\n",
      "Processing file: trustllm_sycophancy.json -> d:\\Paper\\TrustEval-toolkit\\examples/truthfulness_llm\\trustllm_sycophancy_responses.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing items: 100%|██████████| 419/419 [00:40<00:00, 10.43it/s]\n",
      "Processing files:  92%|█████████▏| 11/12 [01:23<00:11, 11.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: trustllm_hallucination.json -> d:\\Paper\\TrustEval-toolkit\\examples/truthfulness_llm\\trustllm_hallucination_responses.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing items: 100%|██████████| 652/652 [00:20<00:00, 32.06it/s]\n",
      "Processing files: 100%|██████████| 12/12 [01:43<00:00,  8.63s/it]\n"
     ]
    }
   ],
   "source": [
    "from trusteval import generate_responses\n",
    "\n",
    "request_type = ['llm']\n",
    "data_folder = base_dir\n",
    "async_list = ['gpt-4o-mini', 'llama-3.1-8B']\n",
    "sync_list = []\n",
    "\n",
    "await generate_responses(\n",
    "    data_folder=data_folder,\n",
    "    request_type=request_type,\n",
    "    async_list=async_list,\n",
    "    sync_list=sync_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Judge Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trusteval import judge_responses\n",
    "\n",
    "data_folder = base_dir + '/final'\n",
    "target_models = []\n",
    "judge_type = 'llm'\n",
    "async_judge_model = ['gpt-4o-mini']\n",
    "\n",
    "await judge_responses(\n",
    "    data_folder=data_folder,\n",
    "    async_judge_model=async_judge_model,\n",
    "    target_models=target_models,\n",
    "    judge_type=judge_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          model  Truthfulness_ratio    qa  qa_context    fc  persona_base  \\\n",
      "0   gpt-4o-mini            0.615492  0.71       0.975  0.75          0.68   \n",
      "1  llama-3.1-8B            0.636675  0.72       0.945  0.50          0.65   \n",
      "\n",
      "   persona_syco  preconception_base  preconception_syco  self_doubt  internal  \\\n",
      "0          0.66                0.65              0.8400      0.2020    0.6566   \n",
      "1          0.67                0.65              0.7475      0.8788    0.5725   \n",
      "\n",
      "   external    halu    syco  delta_persona  delta_preconception  \n",
      "0    0.6325  0.5276  0.1022         0.0294               0.2923  \n",
      "1    0.6975  0.5061  0.1027         0.0308               0.1500  \n"
     ]
    }
   ],
   "source": [
    "from trusteval.dimension.truthfulness.truthfulness_llm.evaluate import run, merge_results\n",
    "run(base_dir, target_models=target_models)\n",
    "merge_results(base_dir, target_models=target_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trusteval import report_generator\n",
    "\n",
    "report_generator(\n",
    "    base_dir=base_dir,\n",
    "    model_type='llm',\n",
    "    aspect='Truthfulness'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
