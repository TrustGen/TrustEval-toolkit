[
    {
        "original_html": "You have reached the cached page for https://link.springer.com/article/10.1007/s12027-020-00629-3Below is a snapshot of the Web page as it appeared on 2024/10/23 (the last time our crawler visited it). This is the version of the page that was used for ranking your search results. The page may have changed since we last cached it. To see what might have changed (without the highlights), go to the current page.Bing is not responsible for the content of this page. Skip to main content Advertisement Account Menu Find a journal Publish with us Track your research Search Cart Home ERA Forum Article Privacy in emergency circumstances: data protection and the COVID-19 pandemic Article Published: 28 September 2020 Volume 21, pages 379–393, (2020) Cite this article Download PDF ERA Forum Aims and scope Privacy in emergency circumstances: data protection and the COVID-19 pandemic Download PDF Emanuele Ventrella1 11k Accesses 18 Citations 1 Altmetric Explore all metrics AbstractThe way we conceive our privacy and the importance which we attach to the protection of our personal data has been heavily impacted by the COVID-19 pandemic. By first providing legal insights on the general discussion about the balance between the fundamental right to privacy and the general public interest, this article describes the most critical and controversial processing operations employed by states to contain the pandemic and mitigate its effects. A focus on the increase in cybercrime during the pandemic then provides insights on the relevant risks and remedies for the security of personal data. Similar content being viewed by others Sacrificing Privacy in the Fight Against Pandemics: How Far Is Too Far? Examples from Bosnia and Herzegovina and Montenegro Chapter © 2021 The Privacy Implications of Using Data Technologies in a Pandemic Article 01 October 2020 The end of privacy for the populace, the person of interest and the persecuted Article 17 July 2017 Use our pre-submission checklist Avoid common mistakes on your manuscript. 1 IntroductionIn the span of just a few months, the COVID-19 pandemic has changed the way we work, socialise and think, impacting almost every aspect of our economy, society and mental health. The way we conceive our privacy and the importance which we attach to the protection of our personal data has also been heavily impacted by this ground-breaking event. As it has put into perspective other fundamental rights which until then we would never have accepted seeing restricted by state measures, the pandemic has required us to balance privacy with health and security.By first providing legal insights on the general discussion about the balance between the fundamental right to privacy and the general public interest, this article will describe the most critical and controversial processing operations employed by states to contain the pandemic and mitigate its effects.Footnote 1 A detailed focus on the European approach to such methodologies and technologies will demonstrate how the highest standards in terms of privacy and data protection can still be maintained, even in exceptional circumstances. Finally, in analysing the increase in cybercrime-related risks to the security of personal data during the pandemic, the article will delineate examples of technical and organisational measures that can be implemented as remedies.2 Privacy in emergency circumstances2.1 The fundamental right to privacy and the general public interestIn order to conscientiously analyse the privacy implications of the COVID-19 pandemic, a preliminary and general discussion on privacy and personal data rights is necessary in order to ensure the temptation of partisan argumentation is resisted. Privacy and the right to data protection are fundamental rights, yet they are not absolute rights. According to philosophical tradition, a right is absolute when it outweighs every other element, including other rights and freedoms, including the moral imperative of saving human lives, and the protection of the efficiency of an economic system.Footnote 2 States of emergency, national interests, and exceptional circumstances have in the past allowed for temporary limitations of fundamental rights such as the right to privacy. Having been defined as “a threat for every country, rich and poor” by the Director-General of the World Health Organisation (WHO), the COVID-19 pandemic is an exceptional circumstance which led countries worldwide to declare states of emergency.Footnote 3According to Art. 52(1) of the Charter of Fundamental Rights of the European Union, limitations on the exercises of the rights and freedoms recognised by the Charter may be made only if they genuinely meet objectives of general interest recognised by the Union.Footnote 4 Specifically concerning privacy, Art. 8(2) of the European Convention on Human Rights enumerates the legitimate aims that may justify an infringement upon the right to respect for private and family life “[…] in the interest of national security, public safety or the economic well-being of the country, for the prevention of disorder or crime, for the protection of health and morals or for the protections of the rights and freedoms of others.”Footnote 5 The European Union General Data Protection Regulation (henceforth GDPR or Regulation)Footnote 6 adds details to these considerations. Recital 4 provides that data protection should always be considered in relation to its function in society and balanced against other fundamental rights. In addition, Art. 23(1) GDPR allows Member States to restrict data subject rights, as well as the data protection principles outlined in Art. 5 GDPR, as long as this is done by way of a legislative measure and respects the essence of those same fundamental rights and freedoms. These restrictions, provided that they are embodied in necessary and proportionate measures of a democratic society, should aim to safeguard, among other things, “important objectives of general public interest […] including monetary, budgetary and taxation matters, public health and social security”.Footnote 72.2 The need to process personal data during a pandemicIn the specific circumstances of a pandemic, processing personal data is necessary in order to take appropriate measures to contain the spread of the virus and subsequently mitigate its effects.Footnote 8 First, the processing of certain types of personal data (such as name, home address, workplace, travel information) can be useful to understand whether an individual might have visited affected areas or met with people exposed to the virus. Secondly, the processing of special categories of personal data (such as health data, including diagnostic test results) is crucial to understand whether an individual shows infection-related symptoms.Data controllers, be they public or private organisations, continue to be subject to standard data protection rules even in emergency circumstances. In the first place, their obligation to rely on a legal basis remains essential to guarantee the lawfulness of processing operations. Relevant personal data other than special category data can be processed for the purposes outlined above in accordance with both Art. 6(1)(d) and (e) GDPR. While the first legal basis allows processing personal data that is necessary to protect the vital interest of individuals (i.e., to save lives), the second can be relied upon to safeguard the public interest or in the exercise of official authority vested in the controller. Given that public interest can only be determined by the law of the Union or of a Member State, Recital 46 GDPR explicitly mentions the monitoring of epidemics as circumstances in which the processing may serve both important grounds of public interest and the vital interest of data subjects.Footnote 9Concerning health data, a legal basis for processing can be found in Art. 9(2)(i) GDPR, and further guidance is provided by Recitals 52 and 54 GDPR. According to the Regulation, the processing of special categories of personal data is permitted when it is necessary for reasons of public interest in the area of public health, “such as protecting against serious cross-border threats to health”.Footnote 10 To make this legal basis actionable, not only guidance and directions are to be provided by public health and other relevant authorities, but also suitable, specific safeguards should be implemented due to the sensitivity of these categories of data.Although it might seem that controllers have ample room for manoeuvre when choosing the appropriate legal bases for processing personal data to contain the spread of a virus, an assessment on proportionality remains the cornerstone in the application of measures that should neither be excessive nor discriminatory. Proportionality considerations should assist in prioritising and safeguarding the human dignity of individuals. For example, divulging the identity of a vulnerable person (such as an individual tested positive for the virus) is rarely necessary and – in most cases – alternative measures that avoid the identification of individuals could be equally effective in warning others of potential exposure.3 Tracking individuals to contain the spread3.1 The use of location data and digital contact tracingDuring recent outbreaks, such as SARS in 2003, information and communication technology (ICT) tools were deployed to rapidly detect sources of infection, clusters of cases and transmission routes.Footnote 11 The COVID-19 pandemic facilitated the dissemination of these methods and instruments, specifically through the use of location data to support the response to the pandemic and by means of tracing contacts of affected individuals to limit the spread of the virus.First, location data was collected for the purpose of producing statistics on the aggregated movement of individuals, irrespective of their health status.Footnote 12 Such data would allow governments to monitor and assess the overall effectiveness of their containment measures (e.g., lockdowns). The use of location data implies that electronic communication service providers or information society service providers’ applications would share aggregated and anonymised datasets indicating the geographical position of terminal equipment (e.g., a smartphone) with public officials, allowing them to track population movements. Although using such techniques would require efforts to remove the ability of linking the data with identified or identifiable natural persons, research has shown that anonymising location data is harder than expected since mobility traces of individuals are inherently unique and highly correlated.Footnote 13Secondly, contact tracing is a monitoring process employed to prevent further transmissions of viruses and which aims to trace back people who have been in close contact with someone who is infected. It can be broken down into three basic steps:Footnote 14 1. contact identification: the practice of identifying contacts, usually by asking about the infected person’s activities and the roles and activities of the people around them. 2. contact listing: the practice of listing contacts of an infected person, informing them of the meaning of their contact status, as well as the necessity to take appropriate measures like quarantine or voluntary isolation. 3. contact follow-up: the practice of regularly following-up with all contacts to monitor symptoms and tests for signs of infections. Traditionally carried out through questionnaires and interviews to infected people, in recent years contact tracing has started to rely also on ICT.Footnote 15 With COVID-19, the employment of ICT tools has become increasingly common and countries across the world have placed confidence in ‘digital contact tracing apps’ to mitigate the consequences of the emergency. With the exception of China and few other countries, such tools have not included the processing of location data and have tried to avoid the collection of extensive amounts of data in a centralised server.Footnote 16For example, the most commonly implemented digital contract tracing systems have required the installation of an app on the smartphones of as many people as possible.Footnote 17 For it to work effectively, the majority of the population of an affected country has needed to be involved, including individuals with symptoms, people in quarantine or isolation, people travelling to high risk areas, or simply whoever wanted to get alerts on the overlaps of their activity maps with those of infected individuals.By first cryptographically generating temporary identifiers every few minutes, these kinds of apps would use Bluetooth Low Energy Technology to detect whether two smartphones, and therefore two people, have come into close physical proximity.Footnote 18 Once this proximity is reached and maintained for long enough to represent meaningful contact, the two apps would share the identifiers among each other. An encrypted list of logged identifiers would then be stored locally on the phone. In case an app user is diagnosed with COVID-19, a verification method involving healthcare professionals would confirm the health status of the affected individual without keeping records on his or her identity. The list of contacts would then be shared in a secured way with public authorities.Footnote 19When someone’s phone is included in the list of identifiers held by an individual diagnosed with COVID-19, that someone would receive a notification by public authorities, together with follow-up information as to whether quarantine or self-isolate. This potentially affected individual would then be required contact local health authorities to monitor symptoms and get tested for the virus. The sooner this testing takes place, the faster public authorities would be able to trace additional contacts related to this person.3.2 The European approachSince the use of location data and digital contact tracing apps to manage the health crisis has been implemented first in countries that are often criticised for a suboptimal protection of individual rights, privacy experts in Europe have looked with a certain degree of suspicion at their possible implications. The most common objection concerned the intrusiveness of these measures as well as their power to enable mass surveillance, creating a dangerous environment that could allow governments to continue collecting sensitive information well beyond the emergency.Footnote 20 Nonetheless, Data Protection Authorities in the EU and the European Data Protection Board (EDPB) have underlined how data protection rules should not and are not intended to hinder the measures that need to be implemented in the fight against the COVID-19 pandemic.Footnote 21 On the contrary, data protection should be considered an essential tool in building the necessary social trust that guarantees the effectiveness of these measures.Concerning the use of location data, national laws implementing the Directive on privacy and electronic communication (henceforth ePrivacy Directive) Footnote 22 set the conditions to lawfully process traffic and location data.Footnote 23 While the first can only be shared with public authorities or other third parties once it has been anonymised by electronic communication service providers, the latter always needs the prior consent of users to be transmitted. Where the information is directly collected from the user’s device, such as location data, the access to this information must be strictly necessary to provide information society services that have been explicitly requested by informed users. It is important to notice that, where location data is effectively anonymised, that data is no longer personal data and can be processed without taking into consideration the obligations of the GDPR.Footnote 24 Additionally, in accordance with Art. 15 of the ePrivacy Directive, exceptional legislative measures adopted by Member States can restrict the scope of the rights and obligations provided by the ePrivacy regime.Footnote 25 These national legislative measures should have the sole purpose of safeguarding public security, and would only allow restrictions that constitute a necessary, appropriate and proportionate measure within a democratic society. At the same time, Member States should put in place adequate safeguards to guarantee, among other things, the right to a judicial remedy for users of electronic communication services.With specific regard to digital contact tracing applications, the European Data Protection Board has defined a “grave intrusion into people’s privacy” the large-scale monitoring of contacts between natural persons.Footnote 26 For this reason, it has conditioned the legitimacy of such instruments to the voluntary adoption by the users, as well as to the respect of precise technical and privacy-related requirements and obligations. While the voluntariness of such tools represents a pre-condition allowing data subjects to decide freely whether or not to use the applications (without suffering from any disadvantage in case they refuse to use it), the other requirements interrelate legal considerations with functional recommendations. These requirements, as outlined by the European Data Protection Board, are illustrated and summarised in the following sub-sections.3.2.1 Lawfulness, fairness and transparencyContact tracing applications involve the storage and/or access to information stored in terminal equipment. For this reason, such applications must process information in compliance with Art. 5(3) ePrivacy Directive.Footnote 27 Insofar as concerns the GDPR, where the processing employed by contact tracing applications does not involve special categories of personal data, the recommended legal basis for such processing can be found in Art. 6(1)(e) GDPR (i.e., public interest). On the other hand, where these applications involve the storage of health data (e.g., in order to monitor the health status of an infected individual), in addition to the above legal basis, Art. 9(2)(h), or (i) can allow such processing on the basis of it being necessary for the purposes of preventive or occupational medicine and healthcare, or for reasons of public interest in the area of public health. While consentFootnote 28 and explicit consentFootnote 29 still represent valid legal bases for the processing of personal data and special categories of personal data in the context of contact tracing applications, the mere fact that the use of such applications takes place on a voluntary basis does not imply that these are recommended legal bases. In fact, where controllers decide to rely on consent and explicit consent, the strict requirements making such legal bases valid must be met.Footnote 30Insofar as concerns transparency, for digital contact tracing applications to be compliant with the EU data protection regime, users should have a clear understanding of what is entailed in the use of such applications at any time and should always remain in control of their data. For this to be possible, users must be provided with clear and understandable information about the processing, as well as with the option to exercise their data subject rights via the application itself.3.2.2 Purpose limitationAccording to the European Data Protection Board, the purpose of digital contact tracing applications must be that of supporting, and not replacing, manual contact tracing performed by qualified health personnel. Applications must be part of a wider public health programme and used only until the point when traditional contact tracing can alone be employed to manage the amount of new infections. Purposes must be specific enough to exclude further uses of these tools, avoiding that apps can be subsequently implemented for commercial or law enforcement purposes that are unrelated to the management of the COVID-19 health crisis. The monitoring of compliance with quarantine and confinement measures, or the overall drawing of conclusions on the location of the user, should be excluded from the available purposes of digital contact tracing applications.3.2.3 Data minimisationThe amount of data processed or exchanged by contact tracing applications must be reduced to the strict minimum. Where the application requires the use of a centralised server, the data processed by that server should be limited. Unrelated information or information which is not needed (such as communication identifiers, messages, call logs, etc.) should not be collected. Information on users’ proximity to one another can and should be collected without processing location data. Other than to the extent to which it is strictly necessary, health data should not be collected except on an optional basis and for the purposes of contact follow-up: i.e., assisting in the decision-making process of informing the user.3.2.4 AccuracyAlthough the occurrence of false positives could be unavoidable, contact tracing applications must necessarily employ methods of data correction and/or verification of subsequent analysis results. Since the erroneous identification as a virus carrier can have a high impact on individuals (e.g., being forced to self-isolation until tested negative), risks to data accuracy must be clearly communicated to the data subject. By inviting developers to keep open the source code of the application and that of its backend, and making publicly available its technical specifications, the European Data Protection Board indicates its wish that any concerned party would audit the code. Wide scrutiny, by stimulating improvements in the code, can also contribute to ensure transparency and correct possible bugs. An evaluation protocol should be developed to ensure the effectiveness of the application from a public health viewpoint is progressively validated throughout all stages of deployment.3.2.5 Storage limitationThe pandemic should not be used as an excuse to put in place disproportionate data retention mandates. The principle of storage limitation should be respected by taking into consideration the true medical needs for storing data (e.g., epidemiology-led justifications such as incubation periods). Once the COVID-19 crisis is over, as a general rule, all personal data kept and processed by contact tracing applications should be anonymised or erased. The “return to normality” must include a strategy to stop the collection of identifiers (e.g., by automatically uninstalling or deactivating the application), initiating a process to delete all collected data from all both mobile applications and servers’ database. Deletion of the application must coincide with the deletion of all locally collected data.3.2.6 Integrity and confidentialityAlthough the European Data Protection Board has endorsed both decentralised and centralised approaches for digital contact tracing applications, the initial phase of the app development should include accurate considerations of the advantages and disadvantages of these approaches.Footnote 31 Adequate security measures should be put in place to make sure possible disadvantages and risks to individuals are mitigated. To secure the data stored in both servers and applications, state-of-the-art cryptographic techniques must be implemented.Footnote 32 The adoption of mutual authentication methods between servers and applications can be used to avoid impersonation and the creation of fake users.The use of the application should not allow users to be directly identified by other users. Potentially exposed individuals can be identified by public authorities only with their agreement. The status of users who report as having tested positive for the virus in the application must be verified in a secure way by, for example, providing a single-use code linked to healthcare professionals.3.2.7 AccountabilityThe controller of any contact tracing application should be determined to ensure accountability. While in some cases national health authorities could be the designated controllers, other controllers may also be envisaged. Where multiple digital contact tracing applications across EU Member States are interoperable, any operation or set of operations for the additional purpose of ensuring interoperability beyond the national level should be assessed separately.Footnote 33 This additional and separate processing should have individual controllers or joint controllers clearly identified.Where the implementation of digital contact tracing applications involves different actors, be they private or public entities, their roles and responsibilities should be carefully outlined, making sure users are informed. The importance of determining roles, responsibilities and relationships has to be considered in light of guaranteeing the exercise of data subject rights.Since the processing of personal data resulting from digital contact tracing applications is likely to produce high risk to the rights and freedoms of data subjects, a data protection impact assessment (DPIA) should always be carried out prior to their deployment.Footnote 344 The security of personal data during the pandemic4.1 The rise in COVID-19-related cybercrimeAccording to the most recent annual cybercrime report by Cybersecurity Ventures, cybercrime is soon going to replace traditional crime in terms of scale and costs. Growing both in frequency and severity, it is estimated cybercrime will cost the world $6 trillion annually by 2021 (up from $3 trillion in 2015).Footnote 35 Representing fertile ground for cybercriminal activities, the COVID-19 pandemic has contributed to this trend by generating a set of unique circumstances that have exposed the vulnerabilities both of society and of organisations. On the one hand, the stress and anxiety caused by the crisis (e.g., the mental health issues caused by the lack of social interactions and physical activity during long periods of lockdown or quarantine) have increased the chances of becoming a victim of opportunistic untargeted attacks.Footnote 36 On the other, the fact that organisations have had to adapt in order to survive to the unique societal challenges brought by the pandemic (e.g., the rapid shift from the physical office to the online virtual workplace) has left assets less protected than before for the sake of impulsive and unprepared business continuity.Footnote 37Both at individual and organisational level, social engineering has represented a useful resource in the hands of cybercriminals, especially during the pandemic. Social engineering is defined as: “the science of using social interaction as a means to persuade an individual or an organisation to comply with a specific request from an attacker where either the social interaction, the persuasion or the request involves a computer-related entity.”Footnote 38 Being, as they are, the backbone of phishing, social engineering techniques have been implemented by cybercriminals to capitalise on the anxieties and fears of their victims and exploit the pandemic for scams and attacks. In March 2020, phishing was reported to have increased by 600%.Footnote 39 Although taking various forms, phishing attacks share the common purpose of convincing individuals to give access to information (in most cases personal data), providing fraudulent opportunities both in the cyber and in the real world.As soon as the COVID-19 pandemic started, malicious actors began registering domains containing the words ‘coronavirus’, ‘covid19’ and ‘corona’.Footnote 40 Using these domains, it was possible for cybercriminals to impersonate government organisations, national health institutions or the WHO, convincing individuals to perform actions under the illusion they were engaging with a legitimate party.Footnote 41 Fake institutional websites were used to promise useful information, practical help, as well as opportunities to donate money in solidarity during the crisis. By also attentively following global trends and news, cybercriminals took advantage of the various governmental announcements of policies in support of the citizenry and the economy to spread phishing emails or text messages. In these communications, criminals would share malicious links with individuals who, by entering their personal data, would then fall victims to financial fraud.Malicious websites have also been used to install malware (i.e., malicious software that can be used to extract data, disrupt service, etc.). Among the most relevant malware examples employed during the pandemic, was that malicious actors installed a java-based malware to a copy of the map released by John Hopkins University to track the expansion of the virus across the world.Footnote 42 Once the plugin was downloaded, the malware would then gain remote access of user’s system, device photos, videos and location data. Other notable examples included fake digital contact tracing apps, employed both in Italy and in Canada that, when installed, took hostage the files on a device by encrypting the data stored in it.Footnote 43 If the user wanted to re-gain access to its data, the perpetrators would request a payment (usually in the form of bitcoins).The latter is the typical example of ransomware, the most common attack on organisations. Normally, cybercriminals would take high-value data and operational assets hostage in order to increase their chances of receiving payments/ransoms. Hospitals, health centres and public institutions have been the preferred target of these attacks during the crisis, since they could not afford to be deprived of their data and systems in such critical circumstances and would be willing to pay. The stretching of resources and personnel numbers in the response to the medical emergency, the COVID-19 pandemic, and the related rise in cybercrime, has demonstrated how the healthcare sector represents the most fragile component of a nation’s critical infrastructure.Footnote 444.2 Securing personal data through technical and organisational measuresIn most cases, cyber threats such as those mentioned in the previous section have an impact on the confidentiality, integrity, or availability of personal data. For this reason, they would probably result in personal data breaches and consequentially force data controllers to act in compliance with a series of obligations and requirements which derive directly from the data protection regime.Footnote 45 Specifically, Section 2 of the GDPR is where these obligations can be found.Businesses and organisation, whether they be private or public entities, are required both to put in place procedures aimed at the protection of personal data and to implement cybersecurity measures at all levels. On the one hand, preventative organisational measures showing consideration of the level of risk and the value of the processed data should be implemented in order to ensure a rapid response. To mention just few of these: data protection risk registers, personal data breach notification procedures, data retention schedules and policies, and business continuity plans. On the other hand, technical measures taking into account of the state of the art of technology, as well as the related costs, should be implemented both in the design phase and at the time of the processing itself. These measures can include two-factor authentication systems, strong password policies and access controls, robust antivirus software and end point protection, patch management and vulnerability management procedures. In addition, and in the light of a holistic approach to data protection and data security, organisations should include training for all staff members as part of their wider cyber resilience strategy.When interviewed by the author, Philip Amann, Head of Strategy of Europol’s European Cybercrime Centre (EC3), provided an analysis of cyber-risks and remedies at this particular moment of crisis. Answering a question on how public organisations should implement measures to increase cyber resilience and mitigate the impact of attacks to the security of personal data, he stated: “Cyber security is a shared responsibility and – while technology can provide baseline protection – a strong focus should be put on human factors. This means that ongoing and targeted training, education, and awareness raising are equally important to technology, and complement technology measures to support a high level of cyber security and resilience. […] Organisations need to manage internal risks and the risks within the environment in which they operate, including the supply chain. This requires having both the technical and organisational measures to ensure the security of systems and information. This includes resources, capabilities, processes and tools to detect, defend and respond effectively and efficiently to cyber attacks. Security, including core principles such as security and privacy by design, needs to be a key element of all business processes and activities of an organisation.”Footnote 46 5 ConclusionAt the time of writing, it is difficult to foresee when – and if – things are going back to ‘normality’. When the impact of COVID-19 on privacy and the protection of personal data first started to become visible, privacy experts in Europe denounced the unavoidable “Big Brother” coming out of the privacy \\(\\mathit{vs}\\). health trade-off. These fears did not overestimate the potential impact of this catastrophic event. They did however underestimate the power and effectiveness of the European data protection regime. The GDPR, its principles and obligations, passed the first major test of their short existence, demonstrating to the world how high privacy standards can be maintained even in emergency circumstances. On the one hand, supervisory authorities have provided useful guidance regarding the development and deployment of invasive measures used to mitigate the effects of the pandemic. On the other, businesses and organisations may have discovered that compliance with the security-related requirements of the GDPR already provided the necessary technical and organisational measures to combat the rise in cybercrime during the pandemic. Although in many ways, the EU was unprepared for the management of the pandemic, it performed better than others at protecting the fundamental right to privacy of its citizens in a time of health crisis. NotesPreliminary versions of the first two sections of this article were published in the form of blogposts by Trilateral Research Ltd: “COVID-19 and Data Protection in Emergency Circumstances”, 16 March 2020 (available at: https://www.trilateralresearch.com/covid-19-and-data-protection-in-emergency-circumstances/) “Desperate times call for desperate measures? Understanding the privacy risks of digital-contact tracing in the COVID-19 fight”, 2 April 2020 (available at: https://www.trilateralresearch.com/dpo/desperate-times-call-for-desperate-measures-understanding-the-privacy-risks-of-digital-contact-tracing-in-the-covid-19-fight/).For a complete discussion on rights and highlighting the difference between absolute and fundamental rights, see Wenar [22].WHO Director-General’s opening remarks at the media briefing on COVID-19, 5 March 2020 (available at: https://www.who.int/dg/speeches/detail/who-director-general-s-opening-remarks-at-the-media-briefing-on-covid-19—5-march-2020).Charter of Fundamental Rights of the European Union, 26 October 2012, 2012/C 326/02.Council of Europe, European Convention for the Protection of Human Rights and Fundamental Freedoms, as amended by Protocols Nos. 11 and 14, 4 November 1950, ETS 5.Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regards to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation), OJ 2016 L 119/1.Art. 23(1)(e) GDPR.Ienca, Vayena [11].Recital 46 indeed clarifies that ‘[s]ome types of processing may serve both important grounds of public interest and the vital interests of the data subject as for instance when processing is necessary for humanitarian purposes, including for monitoring epidemics and their spread or in situations of humanitarian emergencies, in particular in situation of natural and man-made disasters.’Art. 9(2)(i) GDPR. Additionally, Recital 54 specifies that ‘public health should be interpreted as defined in Regulation (EC) No 1338/2008 of the European Parliament and of the Council, namely all elements related to health, namely health status, including morbidity and disability, the determinants having an effect on that health status, health care needs, resources allocated to health care, the provision of, and universal access to, health care as well as health care expenditure and financing, and the cause of mortality’.Ting, Carin, Dzau et al., [20].For example, Google has provided COVID-19 Community Mobility Reports, aimed at providing movements trends over time in response to policies aimed at combating the spread of the virus in over 139 countries worldwide. For additional information, see https://www.google.com/covid19/mobility/.Thompson, Warzel, [21]. For an analysis about the privacy-related benefits of aggregated location data, see Hoffman-Andrews, Crocker, [10].The three steps-definition of contact tracing is implemented in WHO reports and publications. A complete definition is available at WHO [23].Among the first smartphones’ applications developed for contact tracing, the Go.data app was launched during the Ebola outbreak in the Democratic Republic of Congo. Additional information is available at: https://www.afro.who.int/news/speeding-detection-slow-down-ebola-smartphone-app-game-changer-contact-tracing-hotspots.Contact tracing applications processing location data have been implemented in China (Mozur, Zhong, Krolik [15]) and South Korea.Epidemiologists and researchers at the University of Oxford have found that to radically reduce the number of infections, about 56% of the population or about 80% of smartphone users should use the app. Servick [18].Ferretti et al. [9].When a user is declared infected, contact tracing applications can send to a server either the history of proximity contacts that has been obtained through scanning, or the list of their own identifiers that were broadcasted. This contributes to the difference between centralised and decentralised approaches to digital contact tracing. Under the centralised approach, the identifiers of the infected user and those of its contacts are stored in a central database, enabling increased visibility of the data by governments and health services. Examples of such approach have been implemented in France and the UK. Under the decentralised approach, identifiers are generated by the user’s phone and only the identifiers broadcasted by the infected user are shared with the backend server. Examples of this approach are countries adopting the Pan-European Privacy-Preserving Proximity Tracing (PEPP-PT) protocol. DP-3T [5]. On 10 April 10 2020, Apple and Google announced the development of application programming interfaces (APIs) in support of the decentralised approach.Ram, Gray [17]. Amit, Kimhi, Bader et al. [1].Since February 2020, multiple national supervisory authorities have released guidance on their websites to tackle the processing of personal data in the context of the COVID-19 pandemic. On 19 March, the European Data Protection Board adopted a formal statement on the topic via written procedure. The full statement is available at: https://edpb.europa.eu/our-work-tools/our-documents/outros/statement-processing-personal-data-context-covid-19-outbreak_en.Directive 2002/58/EC of the European Parliament and of the Council of 12 July 2002 concerning the processing of personal data and the protection of privacy in electronic communications sector.Art. 6 and Art. 9 ePrivacy Directive.According to the European Data Protection Board Guidelines 04/2020 on the use of location data and contact tracing tools in the context of the COVID-19 outbreak [6], for anonymisation to be effective it should pass the “reasonability test” and be able to remove the ability to link the data with an identifiable natural person against any “reasonable” effort. Three criteria should be taken into consideration to evaluate the robustness of anonymisation: (i) singling-out (i.e., isolating the individual from the group); (ii) linkability (i.e., linking two records concerning the same individual together); and (iii) inference (i.e., deducing previously unknown information about the individual with significant probability).According to Art. 15(1) ePrivacy Directive, ‘Member States may adopt legislative measures to restrict the scope of the rights and obligations provided for in Article 5, Article 6, Article 8(1), (2), (3) and (4), and Article 9 of this Directive when such restrictions constitute a necessary, appropriate and proportionate measure within a democratic society to safeguard national security (i.e., State security), defence, public security, and the prevention, investigation, detection and prosecution of criminal offences or of unauthorised use of electronic communication systems, as referred to in Article 13(1) of Directive 95/46/EC. To this end, Member states may, inter alia, adopt legislative measures providing for the retention of data for a limited period justified on the grounds laid down in this paragraph. All the measures referred to this paragraph shall be in accordance with the general principles of Community law, including those referred to in Article 6(1) and (2) of the Treaty on the European Union.’ European Data Protection Board Guidelines 04/2020 [6].According to Art. 5(3) ePrivacy Directive, the use of electronic communication networks can be only allowed on condition that the concerned user is provided with comprehensive and clear information about the processing. Where the processing is strictly necessary to provide a service explicitly requested by the user, explicit consent is not required.Art. 6(1)(a) GDPR.Art 9(2)(a) GDPR.On 4 May 2020, the European Data Protection Board published an updated version of its Guidelines 05/2020 on consent under Regulation 2016/679 [7]. The Guidelines detail the elements of valid consent: that it be freely given (absence of imbalance of power, absence of conditionality, absence of detriment), specific (specification of purposes against function creep, granularity, separation of information about data processing and other matters), informed, and an unambiguous indication of wishes. The higher standards required for explicit consent are also detailed, specifying how signed statements are not the only way to give an express statement of consent.The European Data Protection Board has also taken the view that a decentralised solution is more in line with the data minimisation principle and that trust in a central server must be limited. Clearly defined governance rules must be determined to manage the central server and ensure its security, including making the access to all data stored in the central server restricted to authorised persons only. Nonetheless, according to research, decentralised infrastructures promoting individual privacy and autonomy can also become vulnerable to corporate or governmental surveillance like their centralised counterparts (De Filippi, [3]).Examples of techniques that can be implemented include: hash functions, symmetric and asymmetric encryption, homomorphic encryption, Bloom filters, etc.The European Data Protection Board has invited Member States to develop applications that are interoperable with other applications across the EU, so that users travelling across multiple Member States can continue be notified efficiently.DPIAs for contact tracing apps have been carried out and released by multiple Member States adopting digital contact tracing solutions. In May, it was reported that the UK’s NHS Test and Trace Service failed to complete the required DPIA prior to launching the app: https://www.politico.eu/article/uk-test-trace-privacy-data-impact-assessement/.Cybersecurity Ventures, [2].Opportunistic untargeted attacks are attacks that base the selection of the victim on their susceptibility to be attacked. Dhanjani, Rios, Hardin [4], p. 223.Panebianco [16].Mouton et al. [14].Shi [19].On 3 April 2020, the European Union Agency for Law Enforcement Cooperation (Europol) published a report on the impact of the COVID-19 pandemic on the cybercrime landscape. The report describes registered domain names as the backbone for many criminal operations. Europol [8], p. 6.Lallie et al. [13].The story of the malware is described in Mouton et al. [14]. The original map and coronavirus resource centre is available here: https://coronavirus.jhu.edu/map.html.Additional information on the Canadian case are available here: https://www.zdnet.com/article/new-crycryptor-ransomware-masquerades-as-covid-19-contact-tracing-app-on-your-device/. Information on the Italian ransomware (named ‘FuckUnicorn’) is available here: https://www.cybersecurity360.it/nuove-minacce/ransomware/immuni-attenti-alla-finta-app-anti-covid-distribuita-via-e-mail-e-un-ransomware/.Khan, Brohi, Zaman [12].Art. 4 GDPR defines personal data breach as “a breach of security leading to the accidental or unlawful destruction, loss, alteration, unauthorised disclosure of, or access to, personal data transmitted, stored or otherwise processed.”The whole interview is available at: https://www.trilateralresearch.com/cyber-threats-and-pandemics-tackling-risk-through-shared-responsibility/.References Amit, M., Kimhi, H., Bader, T., et al.: Mass-surveillance technologies to fight coronavirus spread: the case of Israel. Nat. Med. 26, 1167–1169 (2020). https://doi.org/10.1038/s41591-020-0927-zArticle Google Scholar Cybersecurity Ventures: 2019, official annual cybercrime report (2019). https://www.herjavecgroup.com/the-2019-official-annual-cybercrime-report/ De Filippi, P.: The interplay between decentralization and privacy: the case of blockchain technologies. J. Peer Prod. (7) (2016). Alternative internets. September 14. https://ssrn.com/abstract=2852689 Dhanjani, D., Rios, B., Hardin, B.: Hacking: The Next Generation (2009). O’ Reilley Media Google Scholar DP-3T: Decentralized privacy-preserving proximity tracing, DP-3T (2020). https://github.com/DP-3T/documents/blob/master/DP3T%20White%20Paper.pdf European Data Protection Board (EDPB): Guidelines 04/2020 on the use of location data and contact tracing tools in the context of the COVID-19 outbreak (21 April 2020). https://edpb.europa.eu/sites/edpb/files/files/file1/edpb_guidelines_20200420_contact_tracing_covid_with_annex_en.pdf European Data Protection Board (EDPB): Guidelines 05/2020 on consent under Regulation 2016/679, Version 1.1 (4 May 2020). https://edpb.europa.eu/sites/edpb/files/files/file1/edpb_guidelines_202005_consent_en.pdf European Union Agency for Law Enforcement Cooperation (Europol), Catching the virus – Cybercrime, disinformation and the COVID-19 pandemic (3 April 2020). https://www.europol.europa.eu/publications-documents/catching-virus-cybercrime-disinformation-and-covid-19-pandemic Ferretti, L., et al.: Quantifying SARS-CoV-2 transmission suggests epidemic control with digital contact tracing. Science 368(6491), eabb6936 (2020). https://science.sciencemag.org/content/368/6491/eabb6936Article Google Scholar Hoffman-Andrews, J., Crocker, A.: How to protect privacy when aggregating location data to fight COVID-19. (2020). Electronic Frontier Foundation, April 6. https://www.eff.org/deeplinks/2020/04/how-protect-privacy-when-aggregating-location-data-fight-covid-19 Ienca, M., Vayena, E.: On the responsible use of digital data to tackle the COVID-19 pandemic. Nat. Med. 26, 463–464 (2020). https://doi.org/10.1038/s41591-020-0832-5. Article Google Scholar Khan, N., Brohi, S., Zaman, N.: Ten deadly cyber security threats amid COVID-19 pandemic, TechRxiv (2020). https://www.techrxiv.org/articles/Ten_Deadly_Cyber_Security_Threats_Amid_COVID-19_Pandemic/12278792 Lallie, S., et al.: Cyber security in the age of COVID-19: a timeline and analysis of cyber-crime and cyber-attacks during the pandemic. (2020), arXiv, 21 June 2020. https://arxiv.org/pdf/2006.11929.pdf Mouton, F., et al.: Towards an Ontological Model Defining the Social Engineering Domain. IFIP Advances in Information and Communication Technology (2014) Book Google Scholar Mozur, P., Zhong, R., Krolik, A.: In coronavirus fight, China gives citizens a color code, with red flags. New York Times, 1 March 2020. https://www.nytimes.com/2020/03/01/business/china-coronavirus-surveillance.html Panebianco, M.: Business continuity & crisis management: riflessioni operative sullo stato d’emergenza Covid-19. Federprivacy, 21 April 2020. https://www.federprivacy.org/informazione/primo-piano/business-continuity-crisis-management-riflessioni-operative-ed-umano-centriche-sullo-stato-di-emergenza-covid-19 Ram, N., Gray, D.: Mass surveillance in the age of COVID-19. J. Law Biosci. 7(1), lsaa023 (2020). https://doi.org/10.1093/jlb/lsaa023Article Google Scholar Servick, K.: COVID-19 contact tracing apps are coming to a phone near you. How will we know whether they work? 21 May 2020. https://www.sciencemag.org/news/2020/05/countries-around-world-are-rolling-out-contact-tracing-apps-contain-coronavirus-how Shi, F.: Threat spotlight: coronavirus-related phishing. Barracuda, March 26, 2020. https://blog.barracuda.com/2020/03/26/threat-spotlight-coronavirus-related-phishing/ Ting, D.S.W., Carin, L., Dzau, V., et al.: Digital technology and COVID-19. Nat. Med. 26, 459–461 (2020). https://doi.org/10.1038/s41591-020-0824-5. 2020 Article Google Scholar Thompson, S.A., Warzel, C.: Twelve million phones, one dataset, zero privacy. New York Times, 19 December 2019. https://www.nytimes.com/interactive/2019/12/19/opinion/location-tracking-cell-phone.html Wenar, L.: Rights. In: Zalta, E.N. (ed.) The Stanford Encyclopedia of Philosophy (2020). https://plato.stanford.edu/archives/spr2020/entries/rights/ Google Scholar World Health Organization: Contact tracing in the context of COVID-19. Interim guidance, 10 May 2020. https://www.who.int/publications/i/item/contact-tracing-in-the-context-of-covid-19Download referencesAuthor informationAuthors and AffiliationsTrilateral Research Ltd., London, UKEmanuele VentrellaAuthorsEmanuele VentrellaView author publicationsYou can also search for this author in PubMed Google ScholarCorresponding authorCorrespondence to Emanuele Ventrella.Additional informationPublisher’s NoteSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.Rights and permissionsReprints and permissionsAbout this articleCite this articleVentrella, E. Privacy in emergency circumstances: data protection and the COVID-19 pandemic. ERA Forum 21, 379–393 (2020). https://doi.org/10.1007/s12027-020-00629-3Download citationPublished: 28 September 2020Issue Date: December 2020DOI: https://doi.org/10.1007/s12027-020-00629-3Share this articleAnyone you share the following link with will be able to read this content:Get shareable linkSorry, a shareable link is not currently available for this article.Copy to clipboard Provided by the Springer Nature SharedIt content-sharing initiative KeywordsPrivacyCybercrimeGDPRContact tracingCovid-19 Use our pre-submission checklist Avoid common mistakes on your manuscript. Advertisement Search Search by keyword or author Search Navigation Find a journal Publish with us Track your research Discover content Journals A-Z Books A-Z Publish with us Journal finder Publish your research Open access publishing Products and services Our products Librarians Societies Partners and advertisers Our imprints Springer Nature Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage cookies Your US state privacy rights Accessibility statement Terms and conditions Privacy policy Help and support Cancel contracts here Not affiliated © 2024 Springer Nature",
        "summary": "[[Summary: \nThe article titled \"Privacy in emergency circumstances: data protection and the COVID-19 pandemic\" by Emanuele Ventrella, published in the ERA Forum on September 28, 2020, discusses the significant impact of the COVID-19 pandemic on privacy and data protection. It highlights the tension between the fundamental right to privacy and the public interest during emergencies, particularly in the context of data processing by states to manage the pandemic.\n\nKey points include:\n- The pandemic has necessitated a reevaluation of privacy rights, as governments have implemented measures that may restrict these rights to protect public health.\n- The article references the European Union's legal framework, including the Charter of Fundamental Rights and the General Data Protection Regulation (GDPR), which allow for temporary limitations on privacy rights under specific conditions related to public interest and health.\n- It emphasizes the need for proportionality in data processing, ensuring that measures taken do not excessively infringe on individual rights.\n- The article discusses the use of location data and digital contact tracing as tools for managing the pandemic, detailing how these technologies have evolved and the privacy concerns they raise.\n- It outlines the European approach to contact tracing applications, stressing the importance of voluntary participation, data minimization, and maintaining transparency to build public trust.\n- The rise in cybercrime during the pandemic is addressed, noting that cybercriminals have exploited the crisis, leading to increased phishing attacks and ransomware incidents targeting healthcare institutions.\n- Recommendations for securing personal data include implementing strong technical and organizational measures, ongoing training for staff, and a focus on human factors in cybersecurity.\n- The conclusion reflects on the resilience of the European data protection regime in maintaining privacy standards amidst the challenges posed by the pandemic.\n\nThe article serves as a critical examination of the balance between privacy rights and public health measures during an unprecedented global crisis, underlining the importance of safeguarding personal data even in emergency situations.]]",
        "url": "https://link.springer.com/article/10.1007/s12027-020-00629-3",
        "access_time": "2024-10-26T14:22:26.803975"
    },
    {
        "original_html": "Inforrm's Blog The International Forum for Responsible Media Blog Toggle mobile menu Toggle search field Search for: Home Table of Media Law Cases Resources About Inforrm Search for:Search Button Home Table of Media Law Cases Resources About Inforrm Search for:Search Button Top 10 Privacy and Data Protection Cases of 2021: A selection – Suneet Sharma December 22, 2021 / INFORRM / 1 Comment Inforrm covered a wide range of data protection and privacy cases in 2021. Following my posts in 2018, 2019 and 2020 here is my selection of most notable privacy and data protection cases across 2021: Lloyd v Google LLC [2021] UKSC 50 In the most significant privacy law judgment of the year the UK Supreme Court considered whether a class action for breach of s4(4) Data Protection Act 1998 (“DPA”) could be brought against Google of its obligations as a data controller for its application of the “Safari Workaround”. The claim for compensation was made under s.13 DPA 1998. The amount claimed per person advanced in the letter of claim was £750. Collectively, with the number of people impacted by the processing, the potential liability of Google was estimated to exceed £3bn. Lord Leggatt handed down the unanimous judgement in favour of the appellant Google LLC: “the claim has no real prospect of success. That in turn is because, in the way the claim has been framed in order to try to bring it as a representative action, the claimant seeks damages under section 13 of the DPA 1998 for each individual member of the represented class without attempting to show that any wrongful use was made by Google of personal data relating to that individual or that the individual suffered any material damage or distress as a result of a breach of the requirements of the Act by Google.” The case has been heralded for its central importance in determining the viability of data protection class actions. The case drew wide coverage from Pinsent Masons, Hill Dickinson, Clifford Chance, Bindmans and Stewarts. HRH The Duchess of Sussex v Associated Newspapers Limited [2021] EWHC 273 (Ch) and [2021] EWCA Civ 1810. In February 2021 Meghan, Duchess of Sussex, won her application for summary judgment against the Mail on Sunday. Warby LJ said there were “compelling reasons” for it not to go to trial over its publication of extracts of a private letter to her estranged father, Thomas Markle. He entered judgment for the Duchess in misuse of private information and copyright. There was a news piece on Inforrm and a piece by Dominic Crossley. Associated Newspapers was granted permission appeal and the appeal was heard on 9 and 11 November 2021 with judgment being handed down on 2 December 2021, The Court, Sir Geoffrey Vos MR, Sharp P and Bean LJ, unanimously dismissed the appeal on all grounds, stating: “Essentially, whilst it might have been proportionate to disclose and publish a very small part of the Letter to rebut inaccuracies in the People Article, it was not necessary to deploy half the contents of the Letter as Associated Newspapers did. As the Articles themselves demonstrate, and as the judge found, the primary purpose of the Articles was not to publish Mr Markle’s responses to the inaccurate allegations against him in the People Article. The true purpose of the publication was, as the first 4 lines of the Articles said: to reveal for the first time [to the world] the “[t]he full content of a sensational letter written by [the Duchess] to her estranged father shortly after her wedding”. The contents of the Letter were private when it was written and when it was published, even if the claimant, it now appears, realised that her father might leak its contents to the media.” [106] The case has been analysed on INFORRM by Brian Cathcart. Australian Competition and Consumer Commission v Google LLC (No 2) [2021] FCA 367 The Federal Court of Australia found that Google misled some users about the personal location data it collected through Android devices between January 2017 and December 2018. The Court found that, in providing the option, “Don’t save my Location History in my Google Account”, represented to some reasonable consumers that they could prevent their location data being saved on their Google Account. In actual fact, users need to change an additional setting, separate, to stop their location data being saved to their Google Account. Inforrm had a case comment. Hájovský v. Slovakia [2021] ECHR 591 Mr Hájovský placed an anonymous advert in a national newspaper offering payment to a woman in return for giving birth to his child. An investigative reporter posed as a candidate interested in surrogacy, replied to the advert and secretly filmed the ensuing meetings. These were later complied into a documentary. A national tabloid also covered the story using stills of footage and taking a critical stance of the applicants’ actions. Both stories revealed the applicant’s identity. This prompted the applicant to bring an action against the media groups for violation of his privacy under Slovakian law. The Slovakian courts dismissed the application on the basis that the article contributed to a matter of public interest- the debate around surrogacy for payment and in any event the publishing of the advert had brought a private matter, the applicant’s wish to have a child, into the public domain.The ECtHR found in favour of the applicant. In doing so it reiterated the well-established balancing approach vis a vi privacy and freedom of expression as per Von Hannover and Axel Springer. In this instance the court found that the applicants right to privacy had been violated and that the Slovakian courts has erred in their approach to balancing the competing rights. In doing so the court make key observations about the privacy implications of photographs. Inforrm has a case comment. Warren v DSG Retail Ltd [2021] EWHC 2168 (QB) This case concerned the viability of claims for breach of confidence and misuse of private information against data controllers who have suffered cyber-attacks. In dismissing the claims for breach of confidence and misuse of private information Saini J found that both causes require some form of “positive conduct” by the defendant that is lacking where the cause of the private information being leaked is a cyber-attack. Inforrm had a case comment. 6. ES v Shillington 2021 ABQB 739 In this case the Alberta Court of the Queen’s Bench awarded damages under new “public disclosure of private fact” tort. The case concerned the making public of images of the claimant engaging in sex acts with the defendant- these had been shared during a romantic relationship between 2005 to 2016 where the parties had two children together. The parties had a mutual understanding that the images would not be shared or published anywhere. However, the defendant then proceeded to share the images online, including those involving the sexual assault of the claimant. Delivering judgment for the claimant, Inglis J accepted their submissions that a new “public disclosure of private information” tort should be recognised as a separate cause of action from existing common law statutes. Inforrm has a case comment. Hurbain v Belgium ([2021] ECHR 544) A case in which an order to anonymise a newspaper’s electronic archive was found not to breach the applicant publisher’s right to freedom of expression. This case reflects an important application of the right to be forgotten under article 8 of the Convention. The applicant, Patrick Hurbain, is the president of the Rossel Group which owns one of Belgium’s leading French-language newspapers, Le Soir, of which he was previously Managing Editor. The article in question concerned a series of fatal car accidents and named one of the drivers, G, who had been convicted of a criminal offence for his involvement in the incidents. G made a successful application for rehabilitation in 2006. However, Le Soir created a free, electronic, searchable version of its archives from 1989 onwards, including the article at issue. G relied on the fact that the article appeared in response to a search on his name on Le Soir’s internal search engine and on Google Search. He explained that its availability was damaging to his reputation, particularly in his work as a doctor. The newspaper refused the application by stated it had asked Google to delist/deindex the article. In 2012 G sued Mr Hurbain as editor of Le Sior and was successful domestically. Mr Hurbain then lodged an application with the Strasbourg Court complaining that the anonymisation order was a breach of Article 10. In balancing the article 8 and 10 rights in the case the Strasbourg Court found in favour of G. Informm had a case comment. Peters v Attorney-General on behalf of Ministry of Social Development [2021] NZCA 355 The New Zealand Court of Appeal provided guidance in respect of the tort of invasion of privacy in this high-profile case. In 2017, the Ministry for Social Development (“MSD”) realised that Mr Peters, MP and leader of the New Zealand First Party, had overpaid New Zealand Superannuation (“NZS”). Due to errors NZS had been paid at the single rate when it should have been paid at the partner rate. Mr Peters immediately arranged for the overpaid amount to be repaid. In August 2017 several reporters received anonymous calls in respect of the overpayment. To pre-empt any publicity, Mr Peters released a press statement addressing the incident. He also issued a claim for infringement of the tort of invasion of privacy against several MSD executives. The High Court found the MSD executives were proper recipients of information and thus the claim failed. The Court of Appeal dismissed Mr Peters’ appeal. For an invasion of privacy claim to succeed there is a two “limb” test: the existence of facts in respect of which there was a reasonable expectation of privacy; and that the publicity given to those private facts would be considered highly offensive to an objective reasonable person. The Court agreed that limb one was met on the facts. However, the Court found that Mr Peters did not have a reasonable expectation of protection from disclosure of this information within MSD and from MSD to the relevant Ministers and select staff. As the claimant could not prove that any of defendants had released information to the media. The appeal was dismissed. The case affirmed the removal of the requirement for there to be widespread disclosure and the potential for the removal of the requirement that disclosure be highly offensive. R (Open Rights Group and the 3 million) v Secretary of State for the Home Department and Others [2021] EWCA Civ 800, A case concerning “the lawfulness” immigration exemption found in paragraph 4 of Schedule 2 of the Data Protection Act 2018. This exemption allows those processing personal data for immigration control purposes to refuse to comply with the data subject rights guaranteed by the GDPR to the extent that complying with those provisions would prejudice those purposes. The Court of Appeal found that this exemption was not compliant with Article 23 of the GDPR. There was coverage from Hunton Andrews Kurth and 11KBW. Biancardi v. Italy[2021] ECHR 972 The ECtHR found that an order that the editor of an online newspaper was liable for failing to de-index an article concerning criminal proceedings did not breach Article 10 of the Convention. The case concerned an application for the delisting of an article concerning a fight involving a stabbing in a restaurant which mentioned the names of the those involved including the applicant V.X. Inforrm had a case comment. Suneet Sharma is a junior legal professional with a particular interest and experience in media, information and privacy law. He is the editor of The Privacy Perspective blog. Share this:PrintEmailTwitterFacebookPocketTelegramLinkedInWhatsAppPinterestTumblrRedditLike this:Like Loading... Data Protection, Privacy Suneet SharmaTop 10 Privacy and Data Protection Cases Previous Post Australia: Forget calls for a royal commission into big media players, this is the inquiry we really need Next Post Inforrm is taking a Winter Break 0 Comments 1 Pingback Top 10 Privacy and Data Protection Cases 2022, a selection – Suneet Sharma – Inforrm's Blog Leave a ReplyCancel reply Contact the Inforrm Blog Inforrm can be contacted by email inforrmeditorial@gmail.com Email Subscription Enter your email address to subscribe to this blog and receive notifications of new posts by email. Email Address: Sign me up! Media Law Employment Opportunities Penningtons Manches Cooper, Paralegal – Commercial Dispute Resolution (Reputation Management & Privacy) Edwards Duthie Shamash, Media Law Associate, 3 – 5 years PQE Schillings Senior Associate Schillings Associate Good Law Practice, Defamation Lawyer Brett Wilson, NQ – 4 years’ PQE solicitor Mishcon de Reya, Associate Reputation Protection, 1-4 PQE Slateford, NQ – 2 years’ PQE solicitor Top PostsTop 10 Defamation Cases 2022: a selection - Suneet SharmaLiam Payne: journalistic ethics are often ignored when celebrities die - Polly RipponCase Law, Strasbourg: Hurbain v Belgium, Order to anonymise newspaper archive did not violate Article 10 - Hugh Tomlinson QC and Aidan WillsTop 10 Defamation Cases of 2023: a selection - Suneet SharmaTable of Media Law CasesRecent JudgmentsCategories Academic Algorithms Artificial Intelligence Australia Bosnia Herzegovina Broadcasting Canada Caselaw China Cybersecurity Data Protection EU France Freedom of expression Freedom of Information Germany Government and Policy Harassment Hong Kong Human Rights India Inforrm Injunction Intellectual Property Internet Ireland Israel Italy Journalism Legal Leveson Inquiry Libel Media Media Regulation New Zealand Northern Ireland Open Justice Philippines Phone Hacking Privacy Scotland Social Media South Africa Spain Surveillance Uncategorized United States Search Inforrm’s Blog Search for: Blogroll Alternative Leveson 2 Project Blog Law Online Brett Wilson Media Law Blog Canadian Advertising and Marketing Law Carter-Ruck's News and Insights Cearta.ie – The Irish for Rights Centre for Internet and Society – Stanford (US) Clean up the Internet Cyberlaw Clinic Blog Cyberleagle Czech Defamation Law David Banks Media Consultancy Defamation Update Defamation Watch Blog (Aus) Droit et Technologies d'Information (France) ECHR Blog Fei Chang Dao – Free Speech in China Guardian Media Law Page Hacked Off Blog Information Law and Policy Centre Blog Internet & Jurisdiction Internet Cases (US) Internet Policy Review IP Kat Journlaw (Aus) LSE Media Policy Project Media Reform Coalition Blog Media Report (Dutch) Michael Geist – Internet and e-commerce law (Can) Musings on Media (South Africa) Paul Bernal's Blog Press Gang Press Gazette Media Law Scandalous! Field Fisher Defamation Law Blog Simon Dawes: Media Theory, History and Regulation Social Media Law Bulletin (Norton Rose Fulbright) Strasbourg Observers Transparency Project UK Constitutional Law Association Blog Zelo Street Blogs about Privacy and Data Protection Canadian Privacy Law Blog Data Matters Data protection and privacy global insights – pwc DLA Piper Privacy Matters Données personnelles (French) Europe Data Protection Digest Hawk Talk ICO Blog IP Harbour Mass Privatel Norton Rose Fulbright Data Protection Report Panopticon Blog Privacy and Data Security Law – Dentons Privacy and Information Security Law Blog – Hunton Andrews Kurth Privacy Europe Blog Privacy International Blog Privacy Lives Privacy News – Pogo was right RPC Privacy Blog The Privacy Perspective Blogs about the Media British Journalism Review Jon Slattery – Freelance Journalist Martin Moore's Blog Photo Archive News Blogs and Websites: General Legal issues Carter-Ruck Legal Analysis Blog Human Rights in Ireland Human Rights Info ICLR Blog ICLR Case Commentary Joshua Rozenberg Facebook Law and Other Things (India) LawInSport Letters Blogatory Mills and Reeve Technology Law Blog Open Rights Group Blog RPC's IP Hub RPC's Tech Hub SCOTUS Blog The Court (Canadian SC) The Justice Gap UK Human Rights Blog UK Supreme Court Blog Court, Government, Regulator and Other Resource Sites Australian High Court Canadian Supreme Court Commonwealth Legal Information Institute Cour De Cassation France European Data Protection Board Full Fact.org German Federal Constitutional Court IMPRESS Project IPSO Irish Supreme Court New Zealand Supreme Court NSW Case Law Ofcom Press Complaints Commission Press Council (Australia) Press Council (South Africa) South African Constitutional Court UK Judiciary UK Supreme Court US Supreme Court Data Protection Authorities Agencia Española de Protección de Datos (in Spanish) BfDI (Federal Commissioner for Data Protection)(in German) CNIL (France) Danish Data Protection Agency Data Protection Authority (Belgium) Data Protection Commission (Ireland) Dutch Data Protection Authority European Data Protection Board Information Commissioner's Office Italian Data Protection Authority Scottish Information Commissioner Swedish Data Protection Authority Freedom of Expression Blogs and Sites Backlash – freedom of sexual expression Council of Europe – Freedom of Expression EDRi – Protecting Digital Freedom Free Word Centre Freedom House Freedom of Expression Freedom of Expression Institute (South Africa) Guardian Freedom of Speech Page Index on Censorship Freedom of Information Blogs and Sites All About Information (Can) Campaign for Freedom of Information David Higgerson FOI Man FreedomInfo.org Hawk Talk Open and Shut (Aus) Open Knowledge Foundation Blog Panopticon Blog The Art of Access (US) The FOIA Blog (US) The Information Tribunal UCL Constitution Unit – FOI Resources US Immigration, Freedom of Information Act and Privacy Act Facts Veritas – Zimbabwe Whatdotheyknow.com Inactive and Less Active Blogs and Sites #pressreform Aaronovitch Watch Atomic Spin Bad Science Banksy's Blog Brown Moses Blog – The Hackgate Files California Defamation Law Blog (US) CYB3RCRIM3 – Observations on technology, law and lawlessness. Data Privacy Alert Datonomy Defamation Lawyer – Dozier Internet Law DemocracyFail Entertainment & Media Law Signal (Canada) Forty Shades of Grey Greenslade Blog (Guardian) Head of Legal Heather Brooke IBA Media Law and Freedom of Expression Blog Information and Access (Aus) Informationoverlord ISP Liability IT Law in Ireland Journalism.co.uk Korean Media Law Legal Research Plus Lex Ferenda Media Beak Media Law Journal (NZ) Media Pal@LSE Media Power and Plurality Blog Media Standards Trust Mediabelf Meeja Law Nied Law Blog No Sleep 'til Brooklands panGloss peep beep! Press Not Sorry Primly Stable Responsabilidad En Internet (Spanish) Right2Info Socially Aware Story Curve Straight Statistics Tabloid Watch The IT Lawyer The Louse and The Flea The Media Blog The Public Privacy The Sun – Tabloid Lies The Unruly of Law UK FOIA Requests – Spy Blog UK Freedom of Information Blog Journalism and Media Websites Campaign for Press and Broadcasting Freedom Centre for Law, Justice and Journalism Committee to Protect Journalists Council of Europe – Platform to promote the protection of journalism and safety of journalists ECREA Communication Law and Policy Electronic Privacy Information Centre Ethical Journalism Network European Journalism Centre European Journalism Observatory Frontline Club Hold the Front Page International Federation of Journalists Journalism in the Americas Media Wise Trust MediaAcT Mediadem New Model Journalism – reporting the media funding revolution Reporters Committee for Freedom of the Press Reuters Institute for the Study of Journalism Society of Editors Sports Journalists Association Spy Report – Media News (Australia) The Hoot – the Media in the Sub-Continent Law and Media Tweets 1stamendment Article 19 DanielSolove David Rolph Defamation Update FirstAmendmentCenter Guardian Media Heather Brooke (newsbrooke) humanrightslaw Index on Censorship Internetlaw jonslattery Kyu Ho Youm's Media Law Tweets Leanne O'Donnell Media Law Blog Twitter Media Law Podcast Siobhain Butterworth Media Law Blogs and Websites 5RB Media Case Reports Ad IDEM – Canadian Media Lawyers Association Entertainment and Sports Law Journal (ESLJ) Gazette of Law and Journalism (Australia) International Media Lawyers Association Legalis.Net – Jurisprudence actualite, droit internet Office of Special Rapporteur on Freedom of Expression – Inter American Commission on Human Rights One Brick Court Cases Out-law.com Resources EthicNet – collection of codes of journalism ethics in Europe Handbook of Reuters Journalism House of Commons Select Committee for Culture Media and Sport memoranda on press standards, privacy and libel US Law Blogs and Websites Above the Law ACLU – Blog of Rights Blog Law Blog (US) Blog Law Online Chilling Effects Weather Reports (US) Citizen Media Law Project Courthousenews Entertainment and Law (US) Entertainment Litigation Blog First Amendment Center First Amendment Coalition (US) Free Expression Network (US) Internet Cases – a blog about law and technology Jurist – Legal News and Research Law.com Legal As She Is Spoke Media Law Prof Blog Media Legal Defence Initiative Newsroom Law Blog Privacy and Information Security Law Blog – Hunton Andrews Kurth Privacy Lives Privacy News – Pogo was right Shear on Social Media Law Student Press Law Center Technology and Marketing Law Blog The Hollywood Reporter The Public Participation Project (Anti-SLAPP) The Thomas Jefferson Centre for the Protection of Free Expression The Volokh Conspiracy US Media Blogs and Websites ABA Media and Communications Accuracy in Media Blog Centre for Internet and Society – Stanford (US) Columbia Journalism Review County Fair – a blog from Media Matters (US) Fact Check.org FAIR blog Media Gazer Media Law – a blog about freedom of the press Media Matters for America Media Nation Nieman Journalism Lab Pew Research Center's Project for Excellence in Journalism Regret the Error Reynolds Journalism Institute Blog Stinky Journalism.org Archives October 2024 September 2024 August 2024 July 2024 June 2024 May 2024 April 2024 March 2024 February 2024 January 2024 December 2023 November 2023 October 2023 September 2023 August 2023 July 2023 June 2023 May 2023 April 2023 March 2023 February 2023 January 2023 December 2022 November 2022 October 2022 September 2022 August 2022 July 2022 June 2022 May 2022 April 2022 March 2022 February 2022 January 2022 December 2021 November 2021 October 2021 September 2021 August 2021 July 2021 June 2021 May 2021 April 2021 March 2021 February 2021 January 2021 December 2020 November 2020 October 2020 September 2020 August 2020 July 2020 June 2020 May 2020 April 2020 March 2020 February 2020 January 2020 December 2019 November 2019 October 2019 September 2019 August 2019 July 2019 June 2019 May 2019 April 2019 March 2019 February 2019 January 2019 December 2018 November 2018 October 2018 September 2018 August 2018 July 2018 June 2018 May 2018 April 2018 March 2018 February 2018 January 2018 December 2017 November 2017 October 2017 September 2017 August 2017 July 2017 June 2017 May 2017 April 2017 March 2017 February 2017 January 2017 December 2016 November 2016 October 2016 September 2016 August 2016 July 2016 June 2016 May 2016 April 2016 March 2016 February 2016 January 2016 December 2015 November 2015 October 2015 September 2015 August 2015 July 2015 June 2015 May 2015 April 2015 March 2015 February 2015 January 2015 December 2014 November 2014 October 2014 September 2014 August 2014 July 2014 June 2014 May 2014 April 2014 March 2014 February 2014 January 2014 December 2013 November 2013 October 2013 September 2013 August 2013 July 2013 June 2013 May 2013 April 2013 March 2013 February 2013 January 2013 December 2012 November 2012 October 2012 September 2012 August 2012 July 2012 June 2012 May 2012 April 2012 March 2012 February 2012 January 2012 December 2011 November 2011 October 2011 September 2011 August 2011 July 2011 June 2011 May 2011 April 2011 March 2011 February 2011 January 2011 December 2010 November 2010 October 2010 September 2010 August 2010 July 2010 June 2010 May 2010 April 2010 March 2010 February 2010 January 2010 © 2024 Inforrm's Blog Theme by Anders Norén — Up ↑ Discover more from Inforrm's Blog Subscribe now to keep reading and get access to the full archive. Type your email… Subscribe Continue reading Loading Comments... Write a Comment... Email (Required) Name (Required) Website %d",
        "summary": "[[Summary: \n\nThe blog post titled \"Top 10 Privacy and Data Protection Cases of 2021,\" authored by Suneet Sharma and published on December 22, 2021, presents a selection of significant privacy and data protection cases from 2021. Key cases highlighted include:\n\n1. **Lloyd v Google LLC [2021] UKSC 50**: The UK Supreme Court ruled that a class action for breach of the Data Protection Act 1998 against Google was not viable as the claim lacked evidence of wrongful use of personal data or material damage to individuals. The potential liability for Google was estimated at over £3 billion.\n\n2. **HRH The Duchess of Sussex v Associated Newspapers Limited [2021] EWHC 273 (Ch)**: Meghan Markle won a summary judgment against the Mail on Sunday for publishing parts of a private letter to her father. The appeal by Associated Newspapers was dismissed, emphasizing the private nature of the letter.\n\n3. **Australian Competition and Consumer Commission v Google LLC (No 2) [2021] FCA 367**: The Federal Court of Australia found Google misled users regarding location data collection on Android devices, ruling that additional settings were required to prevent data saving.\n\n4. **Hájovský v. Slovakia [2021] ECHR 591**: The European Court of Human Rights ruled in favor of Mr. Hájovský, finding that his privacy was violated when an investigative journalist exposed his identity in a documentary about surrogacy.\n\n5. **Warren v DSG Retail Ltd [2021] EWHC 2168 (QB)**: This case addressed the liability of data controllers for breaches of privacy due to cyber-attacks, with the court ruling that positive conduct was necessary for such claims.\n\n6. **ES v Shillington 2021 ABQB 739**: The Alberta Court of the Queen’s Bench recognized a new tort for public disclosure of private facts, awarding damages to a claimant whose intimate images were shared without consent.\n\n7. **Hurbain v Belgium ([2021] ECHR 544)**: The court upheld an order for a newspaper to anonymize its archives, balancing the right to privacy against freedom of expression.\n\n8. **Peters v Attorney-General on behalf of Ministry of Social Development [2021] NZCA 355**: The New Zealand Court of Appeal clarified the tort of invasion of privacy, ruling against MP Mr. Peters in a case related to the disclosure of overpayment information.\n\n9. **R (Open Rights Group and the 3 million) v Secretary of State for the Home Department and Others [2021] EWCA Civ 800**: The Court of Appeal found the immigration exemption in the Data Protection Act 2018 non-compliant with GDPR.\n\n10. **Biancardi v. Italy [2021] ECHR 972**: The ECtHR ruled that holding an editor liable for failing to de-index an article did not violate freedom of expression under Article 10 of the Convention.\n\nSuneet Sharma, the author, is a junior legal professional with expertise in media, information, and privacy law. The blog post reflects a comprehensive analysis of the evolving landscape of privacy and data protection law across multiple jurisdictions in 2021.]]",
        "url": "https://inforrm.org/2021/12/22/top-10-privacy-and-data-protection-cases-of-2021-a-selection-suneet-sharma/",
        "access_time": "2024-10-26T14:22:27.617677"
    },
    {
        "original_html": "Skip to content Primary Menu Home About TPP Protecting your privacy Breach of confidence Copyright Data protection rights Defamation Malicious falsehood Misuse of private information Passing off Press complaints Revenge pornography The right to be forgotten Resources Contact Us Privacy Policy Search Search for: The Privacy Perspective Legal blogging on the protection of privacy in the 21st century Top 10 Privacy and Data Protection Cases 2022 January 1, 2023January 1, 2023The Privacy Perspective Inforrm covered a wide range of data protection and privacy cases in 2022. Following my posts in 2018, 2019, 2020 and 2021 here is my selection of notable privacy and data protection cases across 2022. ZXC v Bloomberg [2022] UKSC 5 This was the seminal privacy case of the year, decided by the UK Supreme Court. It was considered whether, in general a person under criminal investigation has, prior to being charged, a reasonable expectation of privacy in respect of information relating to that investigation. The case concerned ZXC, a regional CEO of a PLC which operated overseas. An article was published concerning the PLC’s operations for which ZXC was responsible. The article’s was almost exclusively focused on the contents of a letter sent to a foreign law enforcement agency by a UK law enforcement agency, which was investigating the PLC’s activities in the region. ZXC claimed a reasonable expectation of privacy in relation to the fact and details of a criminal investigation into his activities, disclosed by the letter, and that the publication of the article by Bloomberg amounted to a misuse of that private information. He argued that details of the law enforcement’s investigations into him, the fact that it believed that he had committed criminal offences and the evidence that was sought were all private. At first instance Nicklin J found for the claimant, a finding which was upheld by the Court of Appeal. There were three issues before the UK Supreme Court hearing a further appeal by Bloomberg: (1) Whether the Court of Appeal was wrong to hold that there is a general rule, applicable in the present case, that a person under criminal investigation has, prior to being charged, a reasonable expectation of privacy in respect of information relating to that investigation. (2) Whether the Court of Appeal was wrong to hold that, in a case in which a claim for breach of confidence was not pursued, the fact that information published by Bloomberg about a criminal investigation originated from a confidential law enforcement document rendered the information private and/or undermined Bloomberg’s ability to rely on the public interest in its disclosure. (3) Whether the Court of Appeal was wrong to uphold the findings of Nicklin J that the claimant had a reasonable expectation of privacy in relation to the published information complained of, and that the article 8/10 balancing exercise came down in favour of the claimant. The Court dismissed the appeal on all three grounds. Therefore the precedent is established that there is, as a legitimate starting point, an assumption that there is a reasonable expectation of privacy in relation to the facts of and facts of a criminal investigation at a pre-charge stage. There was an Inforrm case comment on the case, See also Panopticon Blog and 5RB case comment. Driver v CPS [2022] EWHC 2500 (KB) My second case also concerns law enforcement investigations, this time the passing of a file from the CPS and the disclosure of that fact to a third party. Whilst the disclosure did not include the name of the claimant, it was found that “personal data can relate to more than one person and does not have to relate exclusively to one data subject, particularly when the group referred to is small.” In this case, the operation in question, Operation Sheridan, concerned only eight suspects, of which the claimant was one. It should be noted that the claim was one under the Data Protection Act 2018, not the GDPR. In finding for the claimant on the data protection grounds, but dismissing those for misuse of private information, the Judge made a declaration and awarded £250 damages. It should be noted the “data breach was at the lowest end of the spectrum.” See Panopticon Blog on case AB v Chief Constable of British Transport Police [2022] EWHC 2740 (KB) The respondent, an individual with autistic spectrum disorder of the Asperger’s type, claimed that retention of his information by the police in relation to 2011 and 2014 accusations that he touched women inappropriately, was unlawful. The respondent stims, rubbing fabric between his fingers. In both cases no prosecution was brought against AB. The respondent’s claim was based on the fact the data retained was inaccurate and that its retention was a disproportionate inference with his right to respect for his private life under Article 8 of the European Convention of Human Rights. In December 2017, Bristol County Council was contacted with safeguarding concerns about AB- in particular, that he was suffering ongoing trauma due to the appellant maintaining ongoing false allegations against him. As to the claims for inaccuracy “he complained that the records retained by the police inaccurately record that AB put his hands between the legs, and under the dress, of the 2011 complainant. He also implicitly complained that the records of the 2014 incident were inaccurate insofar as they suggested that AB had placed his hand over the complainant’s jeans in the area of her vagina.” It was found at first instance that the police records were inaccurate, that their retention was a disproportionate interference with AB’s article 8 rights and awarded £15,000 for distress, £15,000 for loss of earnings, and £6,000 for aggravated damages. It was found that “the police records in this case are intended to reflect the information that was provided to the police, rather than the underlying facts as to what happened. On this issue I have reached a different conclusion from the judge, with the result that I have concluded that the OSRs are accurate. To this narrow extent, the appeal succeeds.” [95] However, the article 8 finding for the claimant was upheld, as was, accordingly, the judge’s declaration that retention was unlawful and the assessment of damages. Chief Constable of Kent Police v Taylor [2022] EWHC 737 (QB) A breach of confidence claim relating to a series of videos which the defendant was provided by Berryman’s Lace Mawer LLP (“BLM”). The videos were said to contain sensitive information in relation to a vulnerable minor, KDI, who was the subject of an anonymity order in civil proceedings. The videos themselves were particularly sensitive, relating to police interviews of KDI in relation to criminal allegations against them. The claimant sued the CC of Kent Police for damage to his front door which occurred in the course of entering his property to search for child pornography. BLM acted for the CC of Kent Police in relation to this matter. During the course of those proceedings that the defendant was given access to the videos, which were for an unrelated claim. The defendant refused to delete the videos upon request or to explain his dealings with the videos. He instead demanded payment if thousands of pounds for his cooperation with the requests. The Judge accordingly ordered the defendant disclose matters in relation to his dealing with the videos, to ensure confidentiality has not been breached. A further, unusual, order was granted for independent permanent deletion of the videos- it should be noted the order considered the defendants privacy in the coruse of such an inpdenendent assessment being undertaken with the judge stating “I have built in a safeguard in the order I propose to make to limit the nature of the independent IT expert’s role to protect Mr Taylor’s privacy interests”. Various Claimants v MGN [2022] EWHC 1222 (Ch) A case concerning the ongoing phone hacking litigation against Mirror Group Newspapers (“MGN”) in which MGN issued and served applications for summary judgment in 23 individual claims. The judge grouped the claims, with this judgment considering six claimants. It was considered by the judge whether claimants should have been put on notice at various times up until and following the first primary trial in the scandal on 21 May 2015. The judge found that such matters were not “clear-cut” for the purposes of determining whether summary judgment could be entered into; they were more appropriate to be settled at trial. There was a comment on the case on the JMW blog. On 11 August 2022 Andrews LJ refused MGN permission to appeal. Brake v Guy [2022] EWCA Civ 235 The claimants appealed an order dismissing their claim for a final injunction and damages for misuse of private information and breach of confidence. The claim was made in relation to a series of emails sent to and received by the first claimant, Mrs Brake, into a business general enquiries email account. The Court reviewed whether “the judge’s evaluation of the evidence which led him to conclude that they had no reasonable expectation of privacy in respect of the contents of the enquiries account and that the information was not imparted to the Guy Parties in circumstances which gave rise to an obligation of confidence.” Only two of the 3,149 tranche of emails were produced for the judge to consider- he was, understandably, not inclined to accept that there was a reasonable expectation of privacy in relation to the emails on the basis of those two emails alone. The burden of proof was considered to be “a very substantial hurdle” which the claimants had “fallen well short of surmounting it”. The arguments for breach of confidence were advanced on the same grounds and dismissed. The judge concluded “the claimants have put forward no argument before this Court which persuades me that the judge was wrong to conclude that the personal information in the enquiries account was not “imparted in circumstances imparting an obligation of confidence.”” The case is instructive as to the method and approach to be taken when claiming there is a reasonable expectation of privacy or obligation of confidence in relation to a high volume of documents. It also provides a tacit reminder of the difficulties over overcoming first instance privacy decisions on appeal. There was a DLA Piper case comment. TU and RE v Google LLC [2022] EUECJ C-460/20 A case concerning two claimants applying for the delisting of search results under Article 17 of the GDPR. The case is instructive as to the pleading of inaccuracy of data in erasure requests- where it arises and where it does, how such a request should be dealt with: The case states at [72 and 73]: “where the person who has made a request for de-referencing submits relevant and sufficient evidence capable of substantiating his or her request and of establishing the manifest inaccuracy of the information found in the referenced content or, at the very least, of a part – which is not minor in relation to the content as a whole – of that information, the operator of the search engine is required to accede to that request for de-referencing. The same applies where the data subject submits a judicial decision made against the publisher of the website, which is based on the finding that information found in the referenced content – which is not minor in relation to that content as a whole – is, at least prima facie, inaccurate”, and “By contrast, where the inaccuracy of such information found in the referenced content is not obvious, in the light of the evidence provided by the data subject, the operator of the search engine is not required, where there is no such judicial decision, to accede to such a request for de-referencing. Where the information in question is likely to contribute to a debate of public interest, it is appropriate, in the light of all the circumstances of the case, to place particular importance on the right to freedom of expression and of information”. For further analysis please see the Panopticon Blog’s excellent analysis of this case. SMO v TikTok Inc. [2022] EWHC 489 (QB) The former Children’s Commissioner of England’s case against Tik Tok for data protection infringements and misuse of private information was discontinued this year. The result was due to the myriad of procedural issues arising in relation to the case including permission to serve out of jurisdiction, extension of time and permission to serve on UK lawyers instead. The case serves as a warning for claimants seeing to issue data protection claims outside of the jurisdiction of ensuring it is done so in proper time and with consideration of matters such as service outside of jurisdiction. See Panopticon Blog on case and on the discontinuance of the claim. Smith & Other v TalkTalk Telecom Group Plc [2022] EWHC 1311 (QB) A claim under the Data Protection Act 1998 and tort of misuse of private information, following a mass data breach. The case concerned three applications: For strike out of the misuse of private information claim and references to unconfirmed breaches in the particulars; For permission to amend the particulars of claim in light of the case Warren v DSG Retail Ltd [2021] EWHC 2168 (QB); and An application for further information. The misuse of private information claim was dismissed. Although the claim had been repleaded to focus on “acts” rather than “omissions” (in an attempt to avoid the consequences of the Warren decision), the Judge followed his own decision in Warren, holding that the action was, in substance, a claim in negligence and that creating a situation of vulnerability to third party data theft was not a claim in missue of private information. There was an Inforrm post on the case and a two part discussion of the issues here and here. See also the Panopticon Blog on case. This case was the final nail in the coffin of mass data breach claims on CFAs supported by ATE insurance (as these are not available in data protection cases). Unless forming part of group litigation, data breach claims are likely to be transferred to the small claims track (see Stadler v Currys Group Limited [2022] EWHC 160 (QB)). Owsianik v. Equifax Canada Co., 2022 ONCA 813 An appeal arising out of three separate class actions in which the plaintiffs sought to apply the tort of inclusion upon seclusion in “data breach” cases. The Ontario Court of Appeal held that on the facts as pleaded, the defendants did not do anything that could constitute an act of intrusion or invasion into the privacy of the plaintiffs. The intrusions alleged were committed by unknown third-party hackers, acting independently from, and to the detriment of, the interests of the defendants. The defendants’ alleged fault was their failure to protect the plaintiffs by unknown hackers which could not be transformed into an invasion by the defendants of the plaintiffs’ privacy. This decision in Ontario is consistent with the approach of the English court in Case No.9. There were case comments by Blakes and McCarthy Tetrault. Share this:EmailLinkedInTwitterFacebookLike Loading... Related Data Protection Commentary, Privacy Law Commentary, Top 10Article 8, Data privacy, Data Protection, Privacy, Privacy law Previous Article Top 10 Defamation Cases 2022 Next Article Privacy Law in Practice – An Insight into Data Protection Law as an In-House IT Lawyer – Madeleine Weber 3 thoughts on “Top 10 Privacy and Data Protection Cases 2022” Pingback: Quotes from caselaw 7: Driver v CPS [2022] EWHC 2500 KB – a departure from the starting point of a reasonable expectation of privacy in criminal investigations pre-charge on “special facts” and low value data breaches – The Privacy Pingback: Quotes from caselaw 7: Driver v CPS [2022] EWHC 2500 KB – a departure from the starting point of a reasonable expectation of privacy in criminal investigations pre-charge on “special facts” and low value data breaches – The Privacy Pingback: Remote visual support and data privacy compliance | ViiBE Leave a comment Cancel reply Δ Search TPP Search for: Join the TPP Mailing List If you enjoyed our content please provide your email below or follow us to receive our weekly posts: Follow Blog via Email Enter your email address to follow this blog and receive notifications of new posts by email. Email Address: Follow Follow Us LinkedIn Follow The Privacy Perspective on WordPress.com Top Posts & PagesTop 10 Privacy and Data Protection Cases 2022Top 10 Privacy and Data Protection Cases of 2020The Murray factors applied to the Meghan Markle case - when is there a reasonable expectation of privacy?Top 10 Defamation Cases of 2017, a selection – Suneet SharmaArchives July 2024 February 2023 January 2023 December 2022 May 2022 March 2022 February 2022 January 2022 December 2021 November 2021 October 2021 September 2021 August 2021 July 2021 June 2021 May 2021 April 2021 February 2021 January 2021 December 2020 October 2020 September 2020 August 2020 July 2020 June 2020 May 2020 April 2020 January 2020 December 2019 November 2019 October 2019 September 2019 August 2019 July 2019 April 2019 March 2019 February 2019 January 2019 December 2018 November 2018 October 2018 TPP Calendar of Content January 2023 M T W T F S S 1 2345678 9101112131415 16171819202122 23242526272829 3031 « Dec Feb » Legal Disclaimer All views and opinions expressed are my own, are for the purpose of critique and debate and are not intended to, nor constitute, legal advice. All copyright ownership is retained by Suneet Sharma or the respective author. Website Powered by WordPress.com. Comment Reblog Subscribe Subscribed The Privacy Perspective Join 105 other subscribers Sign me up Already have a WordPress.com account? Log in now. The Privacy Perspective Customize Subscribe Subscribed Sign up Log in Copy shortlink Report this content View post in Reader Manage subscriptions Collapse this bar Privacy & Cookies: This site uses cookies. By continuing to use this website, you agree to their use. To find out more, including how to control cookies, see here: Cookie Policy %d",
        "summary": "[[Summary: Output Content]]\n\n**Main Topics:**\n1. Privacy and Data Protection Cases of 2022\n2. Legal precedents established in privacy law\n3. Key rulings from UK courts regarding privacy expectations and data protection\n\n**Notable Cases:**\n\n1. **ZXC v Bloomberg [2022] UKSC 5**\n   - **Court:** UK Supreme Court\n   - **Key Issue:** Reasonable expectation of privacy for individuals under criminal investigation prior to charges.\n   - **Background:** ZXC, a CEO of a PLC, claimed privacy over details of a criminal investigation disclosed by a law enforcement letter published by Bloomberg.\n   - **Outcome:** The Supreme Court upheld the assumption of a reasonable expectation of privacy for individuals under investigation pre-charge.\n\n2. **Driver v CPS [2022] EWHC 2500 (KB)**\n   - **Key Issue:** Disclosure of information related to a criminal investigation.\n   - **Background:** The case involved the passing of a file from CPS to a third party without disclosing the claimant's name but still implicating personal data.\n   - **Outcome:** The court found for the claimant on data protection grounds, awarding £250 in damages.\n\n3. **AB v Chief Constable of British Transport Police [2022] EWHC 2740 (KB)**\n   - **Key Issue:** Lawfulness of retention of police information regarding accusations against an individual with autism.\n   - **Background:** The claimant argued the retention of inaccurate data was a disproportionate interference with his privacy rights.\n   - **Outcome:** The court upheld the claimant’s rights, awarding £36,000 in damages.\n\n4. **Chief Constable of Kent Police v Taylor [2022] EWHC 737 (QB)**\n   - **Key Issue:** Breach of confidence concerning sensitive videos related to a minor.\n   - **Outcome:** The judge ordered the defendant to disclose dealings with the videos and mandated their independent permanent deletion.\n\n5. **Various Claimants v MGN [2022] EWHC 1222 (Ch)**\n   - **Background:** Ongoing phone hacking litigation against Mirror Group Newspapers.\n   - **Outcome:** The judge ruled that issues regarding claimants' notice were not clear-cut and better suited for trial.\n\n6. **Brake v Guy [2022] EWCA Civ 235**\n   - **Key Issue:** Appeal regarding misuse of private information.\n   - **Outcome:** The court upheld the dismissal of the claim, emphasizing the burden of proof on claimants regarding privacy expectations.\n\n7. **TU and RE v Google LLC [2022] EUECJ C-460/20**\n   - **Key Issue:** Delisting search results under GDPR Article 17.\n   - **Outcome:** The case clarified the requirements for substantiating requests for de-referencing based on inaccuracies.\n\n8. **SMO v TikTok Inc. [2022] EWHC 489 (QB)**\n   - **Key Issue:** Data protection infringements and misuse of private information.\n   - **Outcome:** The case was discontinued due to procedural issues.\n\n9. **Smith & Others v TalkTalk Telecom Group Plc [2022] EWHC 1311 (QB)**\n   - **Key Issue:** Mass data breach claims.\n   - **Outcome:** The misuse of private information claim was dismissed, reinforcing that such claims are essentially negligence claims.\n\n10. **Owsianik v. Equifax Canada Co. [2022] ONCA 813**\n    - **Key Issue:** Tort of intrusion upon seclusion in data breach cases.\n    - **Outcome:** The court ruled that the defendants did not invade privacy as the alleged intrusions were by unknown third-party hackers.\n\n**Contradictory Information:**\n- The outcome of the case AB v Chief Constable indicates a successful claim for privacy infringement despite the police records being deemed accurate in some respects, highlighting the complexity and nuances in privacy law.\n\n**Contextual Notes:**\n- The cases reflect ongoing developments in privacy law, particularly in relation to data protection rights, the expectation of privacy during criminal investigations, and the implications of data breaches.\n- The rulings demonstrate a growing recognition of individual privacy rights against institutional disclosures and the balancing of public interest with personal privacy.",
        "url": "https://theprivacyperspective.com/2023/01/01/top-10-privacy-and-data-protection-cases-2022/",
        "access_time": "2024-10-26T14:22:29.232074"
    },
    {
        "original_html": "You have reached the cached page for https://www.enzuzo.com/blog/privacy-breach-examplesBelow is a snapshot of the Web page as it appeared on 2024/10/24 (the last time our crawler visited it). This is the version of the page that was used for ranking your search results. The page may have changed since we last cached it. To see what might have changed (without the highlights), go to the current page.Bing is not responsible for the content of this page. Skip to content Products Build a Privacy Program Manage Data Requests (DSARs) Data Mapping Privacy Impact Assessment Vendor Risk Management Consent Management Consent Management Cookie Banner Generator Google Consent Mode Business Legal Policies Privacy Policy Generator Terms of Service Generator End User License Agreement Subscription Services Agreement Returns Policy Generator Shipping Policy Generator Integrations Shopify App Webflow Consent Plugin Solutions Privacy Policy Generator Cookie Banner Generator Terms of Service Generator Data Requests (DSARs) CCPA Compliance By Industry Ecommerce / Retail Agency Mobile Apps Enterprise Shopify Plus By Regulation GDPR California's CCPA/CPRA Brazil's LGPD Quebec's Law 25 PDPL Pricing Resources Privacy Compliance Scanner Blog Privacy 101 Website Compliance Scanner Help Center Powered by Enzuzo Customer Showcase Case Studies Become a Partner / Reseller Affiliate Program Become an Expert Blog Support Center Privacy 101 Legal Glossary What Is Enzuzo? Free Website Compliance Scanner Log in Get a demo Create a free account Log in Get a demo Create a free account 12 Privacy Breach Examples: Lessons Learned & How to Prevent Them Osman Husain 3/26/24 1:47 PM Table of Contents A privacy breach happens when someone accesses another person’s personal information without his or her permission. It is very similar to a data breach, which happens when someone accesses information without authorization. Many people use the two terms interchangeably, but there is a difference in terms of what information is illegally accessed. A privacy breach specifically refers to breaches that target information about people. A data breach can be more generic and be about things other than people, such as business plans, internal sales data, security breaches, sensitive data, exposed data on the dark web, and other sensitive information. 12 Privacy Breach Examples 2014 Experian Breach U.S. credit monitoring firm Experian suffered a privacy breach involving the personal records of 200 million individuals after a Vietnamese man gained unauthorized access to one of its subsidiaries. According to news reports, Ngo managed to deceive Court Ventures by masquerading as a private investigator from Singapore, ultimately gaining unauthorized access to a personal records database. The details surrounding this breach were exposed when Ngo pleaded guilty to multiple charges in March 2014 at a court in New Hampshire. 2014 Yahoo Breach When your company is in the process of being bought out, the last thing you want the FTC to scrutinize you over is your improper sensitive data handling. For Yahoo, that is exactly what happened in 2016 as they were being acquired by Verizon Communications. In 2013, Yahoo experienced the first of several data breaches by unauthorized third parties, breaches that continued into 2014. However, while Yahoo! worked with both security companies and law enforcement to address the beach, they failed to notify affected user accounts and governments around the world. This continued until 2016, when a user attempted to sell over 200 million Yahoo! accounts and the personal information from over 500 million other Yahoo! users. Yahoo! finally reported the series of breaches to the public in September of 2016, two months after user accounts had been put up for sale and several years after the initial violations occurred. Because they kept the violations to themselves and failed to take proper security precautions, Yahoo! was forced to settle a class action lawsuit for $117.5 million dollars in 2019. Additionally, Verizon acquired Yahoo! at a $350 million dollar discount because of these complications. 2016 MySpace Breach While MySpace no longer has the same global influence that it once did, its legacy is felt through other social media platforms and for having one of the worst privacy breaches in internet history. In May of 2016, Myspace announced that over 360 million accounts had been compromised, with hackers attempting to sell personal details including usernames, passwords, and email addresses. Despite the announcement occurring in 2016, the breach may have occurred as early as 2008, with the last confirmed date breach confirmed to have taken place in 2013. This is important because unlike many of the other companies on this list, MySpace responded swiftly to the discovery and invalidated all passwords created prior to 2013. While it wasn’t a perfect solution, annoying many users, it did allow MySpace to protect many of those affected by the breach. While MySpace had been fined by the FTC in the past for data handling failures, their swift actions to protect customers allowed MySpace to avoid penalties for this privacy breach. 2017 Equifax Breach Credit bureaus handle extremely sensitive personal information, which makes them a frequent target of data hacks. While many companies do a good job of protecting their consumers, one organization that failed to prepare and respond properly was Equifax. The 2017 personal data breach affected citizens in the United States, the United Kingdom, and Canada. In March 2017, Equifax was notified that there was a security exploit in software that they were using, and they were encouraged to update immediately to prevent credit card data theft and a damaging security incident. Equifax failed to do so, and multiple hackers accessed its servers for over two months before a breach was detected. The end result? One hundred forty-seven million US records, 15 million UK records, and 19,000 Canadian records were stolen in the breach. The Equifax breach is an instance of a privacy breach example in Canada and ranks as one of the largest data breaches in the world. Governments around the world found that Equifax had failed in its data handling duties because they didn’t update their software when alerted. They also failed other data handling issues that included poor general security and failure to alert regulatory bodies as soon as possible. The end result was over $575 million in fines, a massive drop off in stock prices due to investor mistrust, and a reputation that Equifax is still trying to repair to this day. 2018 Marriott Breach When one company acquires another, that business should examine everything it acquires with careful detail. Had Marriott International done so, they would have avoided one of the biggest data breaches of all time. In 2018, Marriott discovered a data breach that leaked over 500 million guest records, which led to heavy fines and a significant decrease in the number of guests staying at Marriott hotels in 2019. How did the privacy breach happen? It actually began with another company, Starwoods Hotels. Starwoods was notorious for their poor security and a bad reservation system, which allowed hackers to access guest records in 2014. Marriot acquired Starwoods in 2016, but instead of transferring the old Starwoods hotels into their prosperity reservation system, they used the old one. Marriott also fired most of Starwoods’ IT staff, which left few IT professionals to monitor the Starwoods data. The repercussions for Marriott’s failure to properly integrate Starwoods upon acquiring them were steep. Marriott was nearly fined $123 million dollars, but because they took proper measures when they discovered the breach, they were fined $23.8 million instead. However, there was little that could save their reputation. A year after the data breach was reported, Marriott saw a significant decrease in reservations. Surveys conducted around that time suggested that a quarter of Americans would not stay at Marriott hotels since the breach. 2018 Aadhar Breach in India A database holding the personal information of over a billion Indians was leaked and sold online in 2018. Reports said that the hackers were able to access over 200 websites containing information like names, addresses, and bank details of Indian citizens. The Aadhar database included things like photographs, thumbprints, retina scans and other identifying details of every Indian citizen and were handed over for payments as low as $10 USD per record. Repeated LinkedIn Breaches (2012 & 2021) LinkedIn has established itself as one of the most important platforms for business professionals to connect with each other in the modern age. Unfortunately, that has made the professional network service company a target of repeated hacks and breaches. In 2012, LinkedIn suffered a data breach that affected 167 million users. Due to poor security practices, LinkedIn had to pay $1.25 million to victims and was given a deadline of five years to update their security. LinkedIn has suffered other data and privacy breaches over the years, including a 2021 breach that has affected over 500 million users. LinkedIn claims that this breach was not due to a fault in their security, but publicly obtained data obtained through web scraping. However, organizations are still concerned about LinkedIn's security measures, and are actively being investigated over this breach by organizations like the Italian Data Protection Authority. 2023 Oreo Breach The personal data of more than 50,000 employees at Mondelez International — the parent company of Oreo and Ritz, was exposed by a privacy breach involving a third party vendor in May. A report by Bloomberg said the information stolen included employee dates of birth, social security numbers, and home addresses. The hackers targeted a lawfirm used by Mondelez which held records about its employees. A Mondelez representative said that no internal systems of the company were affected by the breach, and that the firm was cooperating with British law enforcement agencies to unearth more details. Employees were notified about the incident nearly three weeks after it occurred and any long-term repercussions have yet to be ascertained. 2023 Petro Canada Breach The most recent example of a privacy breach comes from Canada, after a damaging cybersecurity incident hit Suncor Energy — one of its largest petroleum companies. Details of the incident are still not clear and the company's systems are not fully operational yet, even a week after the initial outage. The breach caused a countrywide outage of the PetroCanada mobile app, web accounts, payment gateways, and internal systems. It's too early to say how many individual details were leaked by the incident, but the number will likely be substantial. 2023 Okta Privacy Breach Hackers targeted cybersecurity firm Okta in October with the firm initially downplaying the incident, saying it only impacted 130 customers or 1% of its userbase. However, it has now emerged that the attacks were far more damaging with the entire database of its customer support system siphoned off Okta's servers.This includes sensitive personal information including names and email addresses of high-profile clients like Zoom, FedEx, and Peloton. The company notified its users of the latest revelations via a letter delivered Tuesday, Nov 28th. 2024 Giant Tiger Privacy Breach Canadian retailer Giant Tiger was hit by a privacy breach after a third-party vendor it uses was compromised by a cybersecurity incident. The incident leaked customers' names, phone numbers, and email addresses. The company was first alerted to the possibility of a breach in early March, and by 15 March, the outcome was confirmed. Why are privacy breaches so damaging to companies? The most common and harmful privacy breach occurs when a malicious party breaches an organization's security to access consumer information. By targeting major companies, hackers and other data thieves gain access to hundreds of thousands of private consumer records with a single attack. Often stolen information includes addresses, financial information, and personal identification data. In response to these extremely harmful acts, regulations like CCPA, GDPR, PIPEDA, and other data privacy acts have imposed certain requirements on corporate data security. These requirements encourage companies to safeguard consumer information. Furthermore, many legislative acts now require organizations to inform employees, consumers, and the government of data leaks and breaches as soon as they occur. Failure to comply with the data security requirements can result in three major consequences: Increased risk of intrusion. Guidelines to handle data properly aren’t in place just to make business harder for your company. These guidelines are best practices if businesses want to maintain good data security. Failure to follow regulation guidelines means that your company is likely at a high risk to experience a data or privacy breach. Financial damages for data breaches. Regulatory bodies can investigate your organization for non-compliance with data handling laws, and they’ll certainly examine your organization with a keen eye when a breach occurs. If your company is found not to have taken the proper steps to protect consumer data, the financial penalties can be extreme. For 2022, the average global data breach now results in over $4 million dollars in financial damages. Loss of consumer trust. The greatest damage that comes with a privacy breach is the loss of consumer trust. Sometimes a good reputation is all that allows one business to succeed over a competitor. An organization that suffers a preventable privacy breach tells the public they shouldn’t trust this organization with their personal information. A company that loses customer trust probably won't stay in business for long. 👉 Looking to prevent privacy breaches? Our list of the best cybersecurity tools will point you in the right direction. How to Recover From a Data Privacy Breach The above examples are case studies in what not to do when a business prepares and responds to a privacy breach. That being said, even the most secure companies in the world may experience a privacy breach at some point, especially those that hold valuable and sensitive personal information. How should your business respond to a privacy breach? Make sure you do the following: Notify customers and regulatory bodies immediately. As soon as a breach is detected, notify affected customers and regulatory bodies. Most data privacy regulators have resources that can help a business respond to a breach. Additionally, you greatly reduce the risk of being fined for your response if you take immediate action rather than try to cover up the breach. Audit your third-party vendors. Adequate vendor management is key to avoiding third-party risk. For example, in the Giant Tiger breach, the offending party was a vendor of the company. So regularly audit your vendors and make sure they are up to date with the latest security protocols. Or use vendor management software to automate this process. Make sure your business is compliant with global data privacy laws. As explained above, consumer data and privacy regulations exist to help companies safely handle and protect customer data. If yours stays compliant with the latest data privacy regulations, you’ll reduce the risk of data breaches, and if one does occur, your company may likely be forgiven by the regulatory bodies rather than penalized for improper behavior. Rely on Enzuzo for Data Privacy Handling There are many tools that can improve your organizational data privacy handling, each with its own particular features and focuses. Are you looking for a single platform that has everything you need to stay compliant with the latest data privacy regulations? If so, you’ll want to check out the Enzuzo data privacy platform. Enzuzo features quick integration into mobile applications, websites, eCommerce services, Shopify Plus, and more. Worried whether your privacy policies are up to par? Trust our attorney-vetted privacy policy generator along with our terms of service generator and EULA generator. Our platform is packed with features to bolster your consumer data security and reduce the risk of a privacy breach. Contact us today to learn more about the Enzuzo data privacy platform or book a demo to try it out. Stay compliant with GDPR, CCPA, PIPEDA, and other data privacy regulations around the world by working with our team of data privacy experts here at Enzuzo. Osman Husain Osman is the content lead at Enzuzo. He has a background in data privacy management via a two-year role at ExpressVPN and extensive freelance work with cybersecurity and blockchain companies. Osman also holds an MBA from the Toronto Metropolitan University. Data privacy, made easy By Industry Agencies Ecommerce / Retail Enterprise Shopify Plus Mobile Apps Webflow Cookie Plugin By Regulation GDPR CCPA/CPRA LGPD Quebec's Law 25 Cookie Consent Consent Management Cookie Banner Generator Google Consent Mode Compliance Scanner Manage Data DSAR Management Data Mapping Impact Assessment Manage Vendor Risk Legal Policies Privacy Policy Generator Terms of Service Generator EULA Generator SSA Generator Return Policy Generator Resources Blog Help Center Legal Glossary Privacy 101 Guides Compliance Checklist Compare Enzuzo Customers Case Studies Enzuzo Examples Company Contact Us Pricing Get a Demo Become a Partner About Us Copyright © 2024 Enzuzo Legal Stuff Privacy Policy Terms of Service SSA Make a Data Request Manage Cookies",
        "summary": "[[Summary: \n\n**Main Topic:** Privacy Breaches and Examples\n\n**Definition:** \n- A privacy breach occurs when personal information is accessed without permission, distinct from a data breach which can involve various types of unauthorized information access.\n\n**Examples of Privacy Breaches:**\n\n1. **2014 Experian Breach:**\n   - Affected: 200 million individuals.\n   - Unauthorized access by Vietnamese man, Ngo, masquerading as a private investigator.\n   - Exposed when Ngo pleaded guilty in March 2014.\n\n2. **2014 Yahoo Breach:**\n   - Multiple breaches from 2013 to 2014 affecting over 500 million accounts.\n   - Yahoo failed to notify users and authorities, leading to a $117.5 million settlement in 2019 and a $350 million discount on acquisition by Verizon.\n\n3. **2016 MySpace Breach:**\n   - Over 360 million accounts compromised, with breaches possibly dating back to 2008.\n   - MySpace invalidated passwords created before 2013, avoiding further penalties.\n\n4. **2017 Equifax Breach:**\n   - Affected: 147 million US records, 15 million UK records, and 19,000 Canadian records.\n   - Failure to update security software led to a breach that resulted in over $575 million in fines.\n\n5. **2018 Marriott Breach:**\n   - Affected: Over 500 million guest records.\n   - Breach stemmed from poor security practices of acquired Starwoods Hotels.\n   - Fined $23.8 million after taking corrective actions.\n\n6. **2018 Aadhar Breach (India):**\n   - Personal information of over a billion Indians leaked and sold online.\n   - Included sensitive data like photographs and biometric details.\n\n7. **Repeated LinkedIn Breaches (2012 & 2021):**\n   - 2012: 167 million users affected, leading to a $1.25 million settlement.\n   - 2021: Over 500 million users affected, claimed to be from web scraping.\n\n8. **2023 Oreo Breach:**\n   - Affected: Over 50,000 Mondelez International employees.\n   - Data exposed included sensitive personal information.\n\n9. **2023 Petro Canada Breach:**\n   - Caused a nationwide outage in Canada, details on leaked information unclear.\n\n10. **2023 Okta Privacy Breach:**\n    - Initially downplayed, later revealed to involve sensitive data of high-profile clients.\n\n11. **2024 Giant Tiger Privacy Breach:**\n    - Affected customer names, phone numbers, and emails due to a third-party vendor compromise.\n\n**Consequences of Privacy Breaches:**\n- Increased risk of intrusion.\n- Financial damages; average breach costs over $4 million globally.\n- Loss of consumer trust, affecting business sustainability.\n\n**Preventive Measures:**\n- Immediate notification to affected parties and regulators.\n- Regular audits of third-party vendors.\n- Compliance with data privacy laws to mitigate risks.\n\n**Author Information:**\n- Osman Husain, content lead at Enzuzo, with a background in data privacy management and an MBA from Toronto Metropolitan University. \n\n**Enzuzo Services:**\n- Offers tools for data privacy handling, including compliance with GDPR, CCPA, and other regulations.]]",
        "url": "https://www.enzuzo.com/blog/privacy-breach-examples",
        "access_time": "2024-10-26T14:22:29.806390"
    },
    {
        "original_html": "Skip to main content An official website of the United States government Here's how you know Here's how you know Official websites use .gov A .gov website belongs to an official government organization in the United States. Secure .gov websites use HTTPS A lock ( Locked padlock icon ) or https:// means you've safely connected to the .gov website. Share sensitive information only on official, secure websites. Search Log in Dashboard Publications Account settings Log out Search… Search NCBI Primary site navigation Search Logged in as: Dashboard Publications Account settings Log in Search PMC Full-Text Archive Search in PMC Advanced Search Journal List User Guide PERMALINK Copy As a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with, the contents by NLM or the National Institutes of Health. Learn more: PMC Disclaimer | PMC Copyright Notice Proc Assoc Inf Sci Technol. 2021 Oct 13;58(1):357–365. doi: 10.1002/pra2.463 Search in PMC Search in PubMed View in NLM Catalog Add to search COVID‐19 Apps and Privacy Protections from Users' Perspective Tian Wang Tian Wang 1 University of Illinois at Urbana‐Champaign, USA Find articles by Tian Wang 1,✉, Lin Guo Lin Guo 1 University of Illinois at Urbana‐Champaign, USA Find articles by Lin Guo 1, Masooda Bashir Masooda Bashir 1 University of Illinois at Urbana‐Champaign, USA Find articles by Masooda Bashir 1 Author information Article notes Copyright and License information 1 University of Illinois at Urbana‐Champaign, USA * Email: tianw7@illinois.edu ✉Corresponding author. Issue date 2021. 84th Annual Meeting of the Association for Information Science & Technology | Oct. 29 – Nov. 3, 2021 | Salt Lake City, UT. Author(s) retain copyright, but ASIS&T receives an exclusive publication license. This article is being made freely available through PubMed Central as part of the COVID-19 public health emergency response. It can be used for unrestricted research re-use and analysis in any form or by any means with acknowledgement of the original source, for the duration of the public health emergency. PMC Copyright notice PMCID: PMC8646764 PMID: 34901397 Abstract As the spread of the novel coronavirus (COVID‐19) continues to be a global challenge, there have been numerous efforts and actions from both government and private organizations towards keeping their community members healthy and safe. One of the approaches is to use mobile apps to trace contacts and update the status of the infected individuals efficiently and conveniently so that the spread of COVID‐19 can be minimized and contained. While these apps could offer many advantages, it also raises serious privacy concerns for many users and hence possibly refusing to adopt it. In this study, we aim to understand the users' expectations on the privacy protections and the provisions under which they are willing to use COVID‐19 apps. We believe our study results can guide policymakers and app developers on the design, deployment, and acceptability of the COVID‐19 apps that can be widely adopted. Keywords: COVID‐19, Mobile Applications, Privacy Concerns, Privacy ProtectionsINTRODUCTION In December 2019, a novel coronavirus was first identified in Wuhan, China, and it quickly became a global challenge with over 10 million cases worldwide being confirmed within six months according to WHO's situation report (2020). The coronavirus disease in 2019 was further named COVID‐19 by WHO, and the WHO Director General declared it as a public health emergency of international concern in January 2020 (R&D Blue Print, 2020). The COVID‐19 pandemic has had serious negative consequences on individuals around the world, not only by threatening their physical health but also by changing their lifestyles and daily routines. Because of the pandemic lockdown and social distance restrictions, people are forced to start self‐quarantine, gatherings are limited, and telecommuting is encouraged instead of meeting in person. Therefore, it has been critical that the governments/health organizations swiftly respond to the pandemic and assist the ones most in need. As one of the solutions to deal with the COVID‐19 pandemic, mobile technologies have been applied by governments and private organizations around the world to control infectious diseases and promote public health. Numerous mobile apps have been developed as an important tool during the outbreak to help with controlling the COVID‐19 outbreak. Mainly, there are two types of COVID‐19 apps: the status app, which is used to show the user's current disease status, and the contact tracing app, which is used to identify and track the ones that may be in contact with infected individuals. Traditionally, tracing of contacts is done by a public health department, which includes interviewing patients and then calling people who have come into contact with those patients. These recent COVID‐19 apps could potentially offer many advantages comparing with the traditional methods. Not only that the tracing cost is much lower since the cases are automatically detected with individuals reporting their information, but it also could identify the infected individuals more efficiently and quickly considering a large number of mobile users (Rowe, 2020). Many governments from different regions have developed their official COVID‐19 apps. For example, the COVIDSafe developed by the Australian Government Department of Health is an in‐use contact tracing app that helps to keep the community safe during the ongoing pandemic (Cartwright, 2020). By deploying these tracing apps, the governments/organizations devote themselves to minimize the level of exposure to the COVID‐19, and limiting the spread of the virus (Abbas & Michael, 2020). However, even though these apps could help with reducing the community's vulnerability to the COVID‐19 by sharing up‐to‐date information, using these apps may also raise serious privacy concerns for users’ data. For example, a previous study found that although many of the current COVID‐19 apps did not appropriately protect user's data in an anonymous, encrypted, and secured way, these apps also required or allowed different types of access to user's personal and sensitive information (Sharma & Bashir, 2020). Another case study also found that privacy protections have not been effectively addressed in most of the COVID‐19 apps. For example, 60% of the apps selected didn't have explicit data retention controls, and 69% of the apps didn't provide options for users to opt‐in/opt‐out (Sharma et al., 2020). These privacy breaches from the apps may not only violate users’ human rights but also makes individuals more concerned and hesitant to use such apps. In addition, results from a prior study indicated that the risks of privacy violations may lead to a lower willingness of individuals to install the apps (Chan & Saqib, 2021). While privacy considerations for COVID‐19 apps have been a global concern, people in the U.S. and western regions are especially demanding the need for privacy protections if they were to use such apps. For instance, according to a study conducted in June 2019, about 79% of Americans in the study said that they were concerned about how the government or the companies used their personal information (Auxier, 2020). Also, a previous research study found that the U.S. public are more willing to accept the contact tracing apps that use decentralized data storage, which preserves a higher degree of privacy, instead of the ones using centralized data storage (Zhang et al., 2020). Given the severity of the pandemic and the cost‐effective and timely resolution that the mobile apps can provide in curbing the pandemic it is ever more critical that governments/policymakers, health care providers, and app developers in the U.S. and around the world understand users' need and expectation for privacy protections when it comes to their health data and sensitive information if they are to use COVID‐19 apps. In this study, we aim to understand individuals' perspectives on the privacy considerations for the COVID‐19 apps in the United States. While people may be willing to use relevant apps to track new cases or monitor the COVID‐19 trends, they may also be cautious about the information they share with the apps considering the amount of personal and sensitive data it involves. On the other hand, a previous survey study found that two‐thirds of Americans stated their willingness to install a COVID‐19 app to help with controlling the outbreak, even if such an app would collect their location data and health information (Hargittai & Redmiles, 2020). Therefore, the goal of this study is to learn the trade‐off when individuals choose to use such an app: what types of privacy protections are people looking for, and what types of information do they agree to provide to the apps. Specifically, the study will identify the privacy considerations that both privacy advocates and privacy opponents expects from three aspects: information collection and sharing, implementation of privacy protections, and trust and surveillance. By studying individuals' needs of privacy protection provided by the app, results from this study could provide privacy design recommendations to policymakers and app developers so that the future development of relevant apps could be more appropriately aligned with users expectations and therefore leading to wider deployment and adoption in the future.LITERATURE REVIEW A variety of mobile apps have been developed during the COVID‐19 pandemic, and these apps have been very helpful and have become an important part of the strategies to control the outbreak. A prior review study considered the COVID‐19 apps as a valuable tool for both individuals and policymakers to overcome the challenges such as reducing the burden on hospitals, providing access to credible information, and tracking the symptoms of individuals (Kondylakis et al., 2020). However, although the new development of COVID‐19 apps could potentially help with controlling the outbreak and promoting public health, previous studies also identified various privacy violations by these apps. Especially when the existing privacy law does not exactly prevent companies from developing apps that are not compliant with the data protection regulation (Newlands et al., 2020), a lot of those apps only include initial risk assessment without fully being compliant. For example, a prior research study examined the lack of privacy for a Singaporean government's contact tracing mobile app, which allowed the ministry of health to access the patient's data and track whom they have been near (Cho et al., 2020). Also, it is possible that the COVID‐19 apps could be hacked because of security risks (Boutet et al., 2020), and the data collected could be vulnerable to cyberattack and misuse (Open letter, 2020). While it is evident that users are concerned about privacy protections when it comes to mobile apps, they are particularly concerned when their data is being watched and recorded, or when they lose control over their data, and when collected information is being used for other purposes without notice (Xu et al., 2012). In addition, a recent survey study found that users in the U.S. did have privacy protection expectations when it came to COVID‐19 apps even before any such apps were in use. For example, they expressed a preference for having control over their data such as being able to delete their data at any time (Sharma et al., 2020). These privacy expectations tend to be similar from different regions of the world with a research study from the UK reporting that users were worried about increased surveillance by governments, as well as personal data being accessed by third parties (Williams et al., 2020). Nevertheless, it is also important to consider that there is various conceptualization when it comes to privacy protections and while there are those that are advocates of such protections there are others that oppose it. Thus, we aimed to understand views and expectations for privacy in COVID‐19 apps from both advocates of privacy as well as those who are opposed to such protections. We believe this approach provides a balanced assessment on the importance of privacy protections in these types of apps while taking account and considering users' differing baseline views on the role of privacy in society. This additional insight can guide governments, policymakers, and app developing companies the awareness and the critical role that privacy protections plays if wider adoption of such apps is the goal. Cho et al. (2020) argued that a strong guarantee of privacy is essential to encourage the common use of a COVID‐19 contact tracing app. Tang (2020) also recommended that app developers should seek privacy‐preserving contact tracing solutions to encourage potential users to install contact‐tracing apps. Furthermore, since there seems to be a direct link between the public's decision of using COVID19 apps and their perception of how their health data is being protected, more effort and emphasis need to be in place for these users’ expectations. It is shown that such accommodations can be made by some app developers (Ahmed et al. 2020) when they chose to implement decentralized architecture for their COVID‐tracing apps over the centralized architecture in order to enhance the privacy protections on users’ data. Another example is the COVID‐19 app SwissCovid developed by the Swiss Federal Office of Public Health, which requires user's consent to process their data, and only keeps user's ID for 14 days as for data retention (Martin et al., 2020).METHOD To understand individuals' privacy perspectives towards the COVID‐19 apps, we designed and sent a survey with questions related to COVID‐19 experiences to 10,000 students at a midwestern university in the United States in June, 2020. Participants in this survey have a variety of backgrounds. Since we recruited the participants through university emails, majority of participants are students under 29 years old. For those who indicate their ethnicities, 56% of the participants are white, and there are also other ethnic groups (25% Asian, 9% Hispanic/Latino, and 4% Black). While the survey was designed as a comprehensive questionnaire including questions related to different fields, in this study, we only focused on analyzing participants' attitudes towards the two types of COVID‐19 apps: the tracing app and the status app. The scenario of using these two apps were described as follows: Tracing app: The app is used to trace the contacts of people who have been diagnosed with COVID‐19. The tracing app is expected to document where you've been and whom you've been close to. Status app: The app is used to keep track of whether the smartphone's owner has had COVID‐19, whether he or she has been tested for COVID‐19 and is disease‐free, and other indicators of disease status, like current temperature. The status app is expected to show the user's current disease status and could be used to allow people more freedom of movement, such as going back to work and school. Besides surveying the attitudes towards the COVID‐19 apps, we also asked participants to respond on their personal view of privacy protections provided by these apps in three aspects: 1) information collection and sharing, 2) implementation of privacy protections, 3) trust and surveillance. In addition, we assessed participant's baseline views on the role of privacy protections in society and classified users as either Advocates or Opponents in order to better understand privacy expectations from a diverse point of view. After collecting and pre‐processing the data, a total of 729 participants who fully completed the survey were selected. We conducted descriptive statistical analysis on the collected data based on participants” privacy preferences, and also analyzed their inclination on the privacy protections for the two applications. The following section presents our results in two parts: participants’ willingness to use the two apps, and their privacy concerns towards the COVID‐19 apps.RESULTS Willingness to Use the App Tracing App As shown in Table 1, 62% of the participants are willing to use the tracing app. For those participants who chose “Maybe”, many of them exhibit privacy as the major concern. Also, 79% of the participants care about the provider of the tracing app. From their preferences, the CDC ranks the highest, followed by the university and WHO. In other words, they are more comfortable to use the app if it is provided by health‐related authorities or the university. Table 1. Willingness to use a tracing app Selected Survey Question Participants Response Would you be willing to use an tracing app? Yes, I would be willing to use the COVID‐19 tracing app. 455 (62%) No, I would prefer the traditional approach to tracing 153 (21%) Maybe. 121 (17%) If such an app were available for use, would it matter to you who offered the app and controlled your data? Yes, it would matter to me who offered the app and who had access to my data. 574 (79%) No, I'd use the tracing app regardless of who offered it. 106 (15%) Maybe. 49 (7%) Which one of the following options would you prefer (to be the provider of the app)? CDC or any health center 379 (52%) My university 306 (42%) World Health Organization (WHO) 286 (39%) Government 69 (9%) My employer 49 (7%) Private company 33 (5%) Other 32 (4%) Open in a new tabFrom the tree plot in Figure 1, we find that 90% of those who express willingness to use the app, are also willing to receive notifications about contact with COVID‐19 cases. In addition, the app provider generally matters more for those who chose unwilling to use the app, implying that these participants are more concerned about their private information and tend to choose the app more carefully based on the provider. Figure 1. Open in a new tab Tree plot (Top: Willingness to use the tracing app; Middle: Willingness to be noticed their contact with COVID‐19 cases; Bottom: If who offers the tracing app matters)Status App Similar to the tracing app, as shown in Table 2, 69% of the participants would like to use the status app. Also, for those who chose the answer “Maybe”, many of them express their concerns on data safety and privacy. 77% of the participants believed that who offers the app matters. Similar to the tracing app, the medical provider and the university are more trustworthy as the app providers. Table 2. Willingness to use a status app Selected Survey Question Participants Response Would you be willing to use a status app? Yes, I would be willing to use the COVID‐19 status app. 464 (64%) No. 101 (14%) Maybe. 164 (22%) If such an app were available for use, would it matter to you who offered the app and controlled your data? Yes, it would matter to me who offered the app and who had access to my data. 566 (78%) No, I'd use the status app regardless of who offered it. 118 (16%) Maybe. 45 (6%) Open in a new tabAlso similar to the tracing app, the tree plot shown in Figure 2 could tell that the provider of the status app generally matters more for those who chose unwilling to use the app. Figure 2. Open in a new tab Tree plot (Top: Willingness to use Status APP; Bottom: If who offers Status APP matter)Privacy Concerns In general, when participants being asked which is more important for the app, 61% of them (444 participants) chose both Privacy and Safety as the important factors of the app. Comparing the two factors, the Safety of the app (21%) got more attention than the Privacy of the app (17%). Further analysis revealed that those who felt like both safety and privacy are important also showed their concerns on the provider of the status app (as shown in Figure 3). The results also found that if the participant cares about the provider of one of the apps, they are likely to care about provider of the other one as well. Figure 3. Open in a new tab Tree plot (Top: Which is more important for the APP; Middle: If who offers Status APP matter; Bottom: If who offers Tracing APP matter)To understand if individuals' view of privacy relate to their privacy concerns towards the COVID‐19 apps, we divided the participants into two groups based on their answers on the view of privacy: privacy advocate (people who view privacy as a human right, civil liberty, constitutional right, or people's right to make themselves inaccessible to others) and privacy opponent (people who view privacy as negative freedom within society, a mechanism that allows people to keep unfavorable information secretly, or believe privacy invasion on individuals is necessary to ensure national security). After collecting the answers, there are 603 participants in the privacy advocate group and 112 participants in the privacy opponent group. Information Collection and Sharing Table 3 shows the types of information that participants are comfortable or uncomfortable to share with the COVID‐19 apps. We found that the location (60%), personal information such as name (54%), health information (52%), and phone number (42%) are the types of information that participants felt most comfortable to share with the apps. Meanwhile, we also recorded the types of information that participants are uncomfortable to reveal. For example, about 83% of the participants are not willing to share their browsing history, and 80% of them do not want to give the app access to their photos. Table 3. Attitude on types of information shared with the app Selected Survey Question Overall Responses Privacy Advocate Privacy Opponent What type of information are you comfortable to share? Your location 434 (60%) 339 (56.2%) 88 (78.6%) Personal information such as name 395 (54%) 320 (53.1%) 67 (59.8%) Health information 376 (52%) 308 (51.1%) 62 (55.4%) Phone number 303 (42%) 234 (38.8%) 61 (54.5%) Your contacts 119 (16%) 82 (13.6%) 35 (31.3%) Bluetooth 94 (13%) 73 (12.1%) 21 (18.8%) What type of information are you uncomfortable to share? Browsing history 604 (83%) 512 (84.9%) 83 (74.1%) Photos 586 (80%) 495 (82.1%) 81 (72.3%) Contacts 468 (64%) 406 (67.3%) 57 (50.9%) Machine address 373 (51%) 327 (54.2%) 41 (36.6%) Device's operating system 309 (42%) 268 (44.4%) 37 (33.0%) Screen size 268 (37%) 232 (38.5%) 34 (30.4%) Geographical location 232 (32%) 210 (34.8%) 19 (17.0%) Email address 208 (29%) 183 (30.3%) 24 (31.4%) Username 158 (22%) 139 (23.1%) 18 (16.1%) Open in a new tabFor the two different groups, we found that participants in the privacy advocate group are more reserved on sharing sensitive data with the COVID‐19 apps, and they may feel more uncomfortable sharing personal information such as browsing history, photos, phone information, and location, comparing with the privacy opponent group.Implementation of Privacy Protections Table 4 presents participants' preferences on the implementation of privacy protections by the app. As the results showed, over half of the participants (62%) believe that all the privacy protections listed in the survey is necessary for the COVID‐19 apps. Among all the choices, participants value the protection of sensitive information more over the others. In addition, participants in the privacy advocate group demand more privacy protections than the privacy opponent group (more of them choose all the protections as their preference instead of a single answer). Table 4. Preferences on privacy protections Selected Survey Question Overall Responses Privacy Advocate Privacy Opponent What's your preference on the privacy protections provided by the app? All of them 453 (62%) 398 (66%) 46 (41.1%) Protect sensitive information 138 (19%) 98 (16.3%) 38 (33.9%) Preventing unauthorized functionality 78 (11%) 58 (9.6%) 18 (16.1%) Limit permissions 36 (5%) 30 (5%) 6 (5.4%) Regulate mobile app data collection 24 (3%) 19 (3.2%) 4 (3.6%) Open in a new tabTrust and Surveillance Table 5 shows the different app providers that participants trust to protect their privacy. The top two ranked providers are participants' medical providers (29%) and the university (28%). It is noticeable that the federal government and the state government are only trusted by 6% and 5% of the participants accordingly. From the results, we also found that the privacy opponent group is more likely to build trust with any of the app providers (only 4.5% of them choose not to trust anyone to protect their data privacy, comparing to the 10.9% for the privacy advocate group). Table 5. Trust on app providers Selected Survey Question Overall Responses Privacy Advocate Privacy Opponent If such a COVID‐19 app were offered, who would you trust most to protect your privacy? My medical provider 210 (29%) 187 (31%) 20 (17.9%) My university 204 (28%) 165 (27.4%) 36 (32.1%) I would not trust anyone to protect my data privacy 73 (10%) 66 (10.9%) 5 (4.5%) A non‐profit organization 67 (9%) 58 (9.6%) 8 (7.1%) Privacy company (e.g. Google, Apple) 46 (6%) 31 (5.1%) 15 (13.4%) Federal government 41 (6%) 32 (5.3%) 9 (8%) State government 38 (5%) 26 (4.3%) 9 (8%) My health insurer 34 (5%) 24 (4%) 8 (7.1%) My employer 16 (2%) 14 (2.3%) 2 (1.8%) Open in a new tabThe participants' attitudes towards tracking of their information are shown in Table 6. While a lot of the participants (63%) felt acceptable if the government is tracking the location of COVID‐19 cases, a larger number of them are not comfortable if everyone using the app is under the surveillance of the app providers. Similar to the previous results, people who view privacy as an important right (privacy advocate group) are more against the tracking on location of COVID‐19 cases or individuals, while people who view privacy negatively (privacy opponent group) are more supportive on tracking from the government. Table 6. Attitudes on information tracking by the apps Selected Survey Question Overall Responses Privacy Advocate Privacy Opponent Is government tracking on location of COVID‐19 cases acceptable? Very acceptable 203 (28%) 142 (23.5%) 56 (50%) Somewhat acceptable 253 (35%) 214 (35.5%) 36 (32.1%) Not sure 97 (13%) 84 (13.9%) 11 (9.8%) Somewhat unacceptable 76 (10%) 69 (11.4%) 4 (3.6%) Very unacceptable 100 (14%) 94 (15.6%) 5 (4.5%) Is government tracking for everyone acceptable? Very acceptable 31 (4%) 21 (3.5%) 9 (8%) Somewhat acceptable 82 (11%) 56 (9.3%) 26 (23.2%) Not sure 110 (15%) 83 (13.8%) 24 (21.4%) Somewhat unacceptable 167 (23%) 133 (22.1%) 32 (28.6%) Very unacceptable 339 (47%) 310 (51.4%) 21 (18.8%) Open in a new tabDISCUSSION In this research study, we found that most users are willing to use COVID19 status and tracing apps if certain privacy and security protections are designed and implemented. For example, over half of the participants view both safety and privacy as an important factor of the COVID‐19 apps while knowing that they need to provide their personal and sensitive information to the apps while using it. In addition, users are more willing to use tracing and status apps to help with contact tracing if the apps had privacy protections. About 78% of participants who viewed safety and privacy as important factors agreed to use both the status app and tracing app. Based on the results from this study, policymakers and app developers need to take privacy protections more seriously and make those features more explicit if their goal is to encourage more users to adopt the COVID‐19 apps. If we are to address users' privacy concerns and place appropriate protections in order to satisfy users' needs, it is important to understand users' expectations for privacy protections and provide the protections in the COVID‐19 apps to increase the usage. According to many survey results, most participants are reserved on providing their sensitive information to the COVID‐19 apps, while only a small percentage are open to give their health and personal data to the app. For example, only 16% of our study participants feel comfortable in share their contacts. In addition, participants worry about the level of surveillance and lack trust in certain entities that may provide the COVID‐19 app. In our survey, 70% of participants reported that it was unacceptable if the government is tracking everyone, instead, they are more comfortable if the app only tracks users' locations (73% rated acceptable). Also, participants tend to have more trust towards some entities that they are more familiar with instead of the governments. Since the survey was sent to college students, about one‐third of our participants chose the University as the one entity that they would trust the most to protect their privacy. These results imply that policymakers still need to consider trust with individuals as an important factor when asking them to use relevant apps. The study also found that most participants prefer and expects privacy protections for COVID‐19 apps regardless of whether they are Advocates or Opponents of privacy protections in general. While privacy advocate participants are more reserved to share their personal and sensitive information with the COVID‐19 apps, they still demand more comprehensive privacy protections from the apps and are less likely to trust the app providers to protect their information. In contrast, privacy opponent participants who view privacy as negative freedom or believe privacy invasion is necessary report being more acceptable of a government tracking location or personal information during the COVID‐19 pandemic. Nonetheless, the results of this study shows that while there are differing views on the role of privacy protections in society when it comes to COVID‐19 apps privacy protections are critical to users adoption of such apps and therefore app providers and designers are encouraged to implement comprehensive privacy protections and make it explicit in order to satisfy users' needs. Furthermore, the above findings regarding users' privacy protection expectations even when accounting for their baseline views regarding privacy in general reveals another vital aspect that needs further examination. This aspect is considering privacy expectations from an underrepresented population. Previous research shows that under‐represented minority individuals distrust such collection of information and worry about how that information may be used to discriminate or exclude them in some way (Ringelheim, 2008). For example, a previous report revealed that ethnic minority groups are at higher risk of oversurveillance after protests (Privacy International, 2020). Because of the possible risks of privacy violations and discriminations, minority groups might seek more privacy protections and be more careful about sharing their information. As shown by our study results, participants from minority groups such as the Hispanic/Latino participants are more concerned about providing their personal information with COVID‐19 apps comparing with White participants, especially when it comes to sharing their health information (61% for Hispanic/Latino, 48.8% for White) and phone number (47.5% for Hispanic/Latino, 40.5% for White). Therefore, it is critical to consider all of these individual differences when designing relevant apps in order to minimize the risk of discrimination and mistrust.LIMITATIONS While our study only recruited participants from a public midwestern university, it is necessary to involve people in different age groups and with different backgrounds to have a more comprehensive understanding of individuals' privacy concerns in future studies. Also, since the survey was conducted and sent out during the early stage of the COVID‐19 outbreak (July 2020), the results are mostly a reflection of participants' expectations of the COVID‐19 apps in the first six months of the pandemic and their perspectives may have changed after they have used the apps.CONCLUSION In conclusion, our study results show that while many people are willing to use COVID‐19 status and tracing apps, they also have concerns about the information that is being collected and expect appropriate privacy protections for the use of their personal and health data. We believe these findings are essential when designing, developing, and deploying pandemic‐related apps. If users' expectations are met, then adoption of technology often increases and since the ultimate goal is to have more users adopt such apps in times of a health crisis, we cannot afford to ignore such expectations.Contributor Information Tian Wang, Email: tianw7@illinois.edu. Lin Guo, Email: linguo4@illinois.edu. Masooda Bashir, Email: mnb@illinois.edu.REFERENCES Abbas, R. , & Michael, K. (2020). COVID‐19 contact trace app deployments: Learnings from Australia and Singapore. IEEE Consumer Electronics Magazine, 9(5), 65–70. [Google Scholar] Ahmed, N. , Michelin, R. A. , Xue, W. , Ruj, S. , Malaney, R. , Kanhere, S. S. , … Jha, S. K. (2020). A survey of covid‐19 contact tracing apps. IEEE Access, 8, 134577–134601. [Google Scholar] Auxier, B. (2020). How Americans see digital privacy issues amid the COVID‐19 outbreak. In Pew Research Center. Retrieved from (https://www.pewresearch.org/fact‐tank/2020/05/04/how‐americans‐see‐digital‐privacy‐issues‐amid‐the‐covid‐19‐outbreak/). [Google Scholar] Boutet, A. , Bielova, N. , Castelluccia, C. , Cunche, M. , Lauradoux, C. , Le Métayer, D. , & Roca, V. (2020). Proximity tracing approaches‐comparative impact analysis. INRIA Grenoble‐Rhone‐Alpes: Doctoral dissertation. [Google Scholar] Cartwright, J. (2020). The Government's COVID‐19 tracking app is called CovidSafe and is launching today. In techAU. Retrieved from (https://techau.com.au/the‐governments‐covid‐19‐tracking‐app‐is‐called‐covidsafe‐and‐is‐launching‐today/). [Google Scholar] Chan, E. Y. , & Saqib, N. U. (2021). Privacy concerns can explain unwillingness to download and use contact tracing apps when COVID‐19 concerns are high. Computers in Human Behavior, 119, 106718. [DOI] [PMC free article] [PubMed] [Google Scholar] Cho, H. , Ippolito, D. , & Yu, Y. W. (2020). Contact tracing mobile apps for COVID‐19: Privacy considerations and related trade‐offs. arXiv preprint arXiv:2003.11511. [Google Scholar] Fife, E. , & Orjuela, J. (2012). The privacy calculus: Mobile apps and user perceptions of privacy and security. International Journal of Engineering Business Management, 4(Godište 2012), 4‐11. [Google Scholar] Hargittai, E. , & Redmiles, E. (2020). Will Americans Be Willing to Install COVID‐19 Tracking Apps? In Scientific American. Retrieved from (https://blogs.scientificamerican.com/observations/will‐americans‐be‐willing‐to‐install‐covid‐19‐tracking‐apps/). Martin, T. , Karopoulos, G. , Hernández‐Ramos, J. L. , Kambourakis, G. , & Nai Fovino, I. (2020). Demystifying COVID‐19 digital contact tracing: A survey on frameworks and mobile apps. Wireless Communications and Mobile Computing, 2020. [Google Scholar] Newlands, G. , Lutz, C. , Tamò‐Larrieux, A. , Villaronga, E. F. , Harasgama, R. , & Scheitlin, G. (2020). Innovation under pressure: Implications for data privacy during the Covid‐19 pandemic. Big Data & Society, 7(2), 2053951720976680. [Google Scholar] Open letter . (2020). Joint statement on contact tracing. Retrieved from (https://drive.google.com/file/d/1OQg2dxPu‐x‐RZzETlpV3lFa259Nrpk1J/view). [Google Scholar] Privacy International . (2020). Ethnic minorities at greater risk of oversurveillance after protests. Retrieved from (https://privacyinternational.org/news‐analysis/3926/ethnic‐minorities‐greater‐risk‐oversurveillance‐after‐protests). [Google Scholar] R&D Blue Print . (2020). COVID‐19 Public Health Emergency of International Concern (PHEIC) Global research and innovation forum: Towards a research roadmap. In World Health Organization. Retrieved from (https://www.who.int/publications/m/item/covid‐19‐public‐health‐emergency‐of‐international‐concern‐(pheic)‐global‐research‐and‐innovation‐forum). [Google Scholar] Ringelheim, J. (2008). Minority protection, data collection and the right to privacy. European Yearbook of Minority Issues Online, 6(1), 51–77. [Google Scholar] Rowe, F. (2020). Contact tracing apps and values dilemmas: A privacy paradox in a neo‐liberal world. International Journal of Information Management, 55, 102178. [DOI] [PMC free article] [PubMed] [Google Scholar] Sharma, T. , & Bashir, M. (2020). Use of apps in the COVID‐19 response and the loss of privacy protection. Nature Medicine, 26(8), 1165–1167. [DOI] [PubMed] [Google Scholar] Sharma, T. , Wang, T. , & Bashir, M. (2020). Advocating for Users' Privacy Protections: A Case study of COVID‐19 apps. In 22nd International Conference on Human‐Computer Interaction with Mobile Devices and Services (MobileHCI '20). Association for Computing Machinery, New York, NY, USA, Article 22, 1–4. [Google Scholar] Situation Report – 162 . (2020). In World Health Organization. Retrieved from (https://www.who.int/docs/default‐source/coronaviruse/20200630‐covid‐19‐sitrep‐162.pdf?sfvrsn=e00a5466_2). [Google Scholar] Tang, Q. (2020). Privacy‐preserving contact tracing: current solutions and open questions. arXiv preprint arXiv:2004.06818. [Google Scholar] Williams, S. N. , Armitage, C. J. , Tampe, T. , & Dienes, K. (2020). Public attitudes towards COVID‐19 contact tracing apps: A UK‐based focus group study. Health Expectations. [DOI] [PMC free article] [PubMed] [Google Scholar] Xu, H. , Gupta, S. , Rosson, M. B. , & Carroll, J. M. (2012). Measuring mobile users' concerns for information privacy. [Google Scholar] Zhang, B. , Kreps, S. , McMurry, N. , & McCain, R. M. (2020). Americans' perceptions of privacy and surveillance in the COVID‐19 pandemic. PLoS One, 15(12), e0242652. [DOI] [PMC free article] [PubMed] [Google Scholar] Articles from Proceedings of the Association for Information Science and Technology. Association for Information Science and Technology are provided here courtesy of Wiley ACTIONS View on publisher site PDF (619.2 KB) Cite Collections Permalink PERMALINK Copy RESOURCES Similar articles Cited by other articles Links to NCBI Databases Cite Copy Download .nbib .nbib Format: AMA APA MLA NLM Add to Collections Create a new collection Add to an existing collection Name your collection * Choose a collection Unable to load your collection due to an error Please try again Add Cancel Follow NCBI NCBI on X (formerly known as Twitter) NCBI on Facebook NCBI on LinkedIn NCBI on GitHub NCBI RSS feed Connect with NLM NLM on X (formerly known as Twitter) NLM on Facebook NLM on YouTube National Library of Medicine 8600 Rockville Pike Bethesda, MD 20894 Web Policies FOIA HHS Vulnerability Disclosure Help Accessibility Careers NLM NIH HHS USA.gov Back to Top",
        "summary": "[[Summary: \n\n**Title:** COVID‐19 Apps and Privacy Protections from Users' Perspective\n\n**Authors:** \n- Tian Wang, University of Illinois at Urbana‐Champaign, USA\n- Lin Guo, University of Illinois at Urbana‐Champaign, USA\n- Masooda Bashir, University of Illinois at Urbana‐Champaign, USA\n\n**Publication Details:**\n- Journal: Proceedings of the Association for Information Science and Technology\n- Date: October 13, 2021\n- DOI: 10.1002/pra2.463\n- PMCID: PMC8646764\n- PMID: 34901397\n\n**Context:**\nThe study explores user expectations regarding privacy protections in mobile applications designed for COVID-19 contact tracing and status monitoring. It aims to guide policymakers and app developers in creating widely accepted COVID-19 applications.\n\n**Key Findings:**\n1. **Background on COVID-19:** \n   - The novel coronavirus was identified in December 2019, leading to over 10 million cases globally by mid-2020. The WHO declared it a public health emergency in January 2020.\n   - COVID-19 has significantly impacted daily routines, leading to self-quarantine and increased reliance on technology for public health measures.\n\n2. **Types of COVID-19 Apps:**\n   - **Status Apps:** Track users' health status regarding COVID-19.\n   - **Contact Tracing Apps:** Identify and track individuals who may have been in contact with infected persons.\n\n3. **Privacy Concerns:**\n   - Despite the potential benefits of these apps, privacy issues are a significant barrier to adoption. Many current apps do not adequately protect user data.\n   - Studies highlighted that a majority of COVID-19 apps lack proper data retention controls and user opt-in/out options.\n\n4. **User Perspectives:**\n   - A survey conducted with 729 students revealed:\n     - 62% willing to use a tracing app; 64% willing to use a status app.\n     - Privacy concerns were the primary reason for hesitancy in app adoption.\n     - 79% of participants preferred apps provided by trusted health organizations.\n\n5. **Privacy Expectations:**\n   - Participants expressed a strong preference for privacy protections, with 61% indicating that both privacy and safety are important factors.\n   - 83% were uncomfortable sharing browsing history, and 80% were hesitant to share photos.\n\n6. **Trust in App Providers:**\n   - The most trusted app providers were medical providers (29%) and universities (28%). Only 6% trusted the federal government.\n\n7. **Demographic Insights:**\n   - Participants were predominantly under 29 years old, with a majority identifying as white, followed by Asian, Hispanic/Latino, and Black ethnicities.\n   - Privacy advocates (603 participants) were more reserved in sharing personal information compared to privacy opponents (112 participants).\n\n8. **Recommendations for App Developers:**\n   - Implement comprehensive privacy protections and make them explicit to encourage user adoption.\n   - Consider the differing perspectives on privacy when designing apps to minimize mistrust and discrimination.\n\n**Limitations:**\n- The study's focus on a single university may not represent broader demographic views on privacy.\n- Insights reflect users' expectations during the early stages of the pandemic and may not account for changes in perceptions over time.\n\n**Conclusion:**\nThe study emphasizes the importance of addressing privacy concerns to enhance the adoption of COVID-19 apps, highlighting the need for effective privacy protections aligned with user expectations.]]",
        "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8646764/",
        "access_time": "2024-10-26T14:22:33.767755"
    },
    {
        "original_html": "You have reached the cached page for https://www.mondaq.com/unitedstates/privacy-protection/785230/case-studies-high-profile-cases-of-privacy-violationBelow is a snapshot of the Web page as it appeared on 2024/10/22 (the last time our crawler visited it). This is the version of the page that was used for ranking your search results. The page may have changed since we last cached it. To see what might have changed (without the highlights), go to the current page.Bing is not responsible for the content of this page. United States Home > United States > Privacy > Privacy Protection About Mondaq Topics Back Topics Accounting and Audit Antitrust/Competition Law Cannabis & Hemp Compliance Consumer Protection Coronavirus (COVID-19) Corporate/Commercial Law Criminal Law Employment and HR Energy and Natural Resources Environment Family and Matrimonial Finance and Banking Food, Drugs, Healthcare, Life Sciences Government, Public Sector Immigration Insolvency/Bankruptcy/Re-Structuring Insurance Intellectual Property International Law Law Department Performance Law Practice Management Litigation, Mediation & Arbitration Media, Telecoms, IT, Entertainment Privacy Real Estate and Construction Strategy Tax Technology Transport Wealth Management Webinars Comparative Guides Firm Directory Advice Centers Blog Mondaq Awards Newsletters Log In Register Contact Us Copy Link LinkedIn X/Twitter Facebook Copy Link LinkedIn X/Twitter Facebook ARTICLE 1 March 2019 Case Studies: High-Profile Cases of Privacy Violation SG Smith Gambrell & Russell More Contributor Firm Page Explore Firm Details The scenario: In August 2018, the FTC announced an expanded settlement with Uber Technologies for its alleged failure to reasonably secure sensitive data in the cloud ... United States Privacy Authors Case Studies: Recent FTC Enforcement Actions - High-Profile Cases of Privacy Violation: Uber, Emp Media, Lenovo, Vizio, VTech, LabMD Uber Technologies The scenario: In August 2018, the FTC announced an expanded settlement with Uber Technologies for its alleged failure to reasonably secure sensitive data in the cloud, resulting in a data breach of 600,000 names and driver's license numbers, 22 million names and phone numbers, and more than 25 million names and email addresses. The settlement: The expanded settlement is a result of Uber's failure to disclose a significant data breach that occurred in 2016 while the FTC was conducting its investigation that led to the original settlement. The revised proposed order includes provisions requiring Uber to disclose any future consumer data breaches, submit all reports for third-party audits of Uber's privacy policy and retain reports on unauthorized access to consumer data.2 Emp Media Inc. (Myex.com) The scenario: The FTC joined forces with the State of Nevada to address privacy issues arising from the \"revenge\" pornography website, Myex.com, run by Emp Media Inc. The website allowed individuals to submit intimate photos of the victims, including personal information such as name, address, phone number and social media accounts. If a victim wanted their photos and information removed from the website, the defendants reportedly charged fees of $499 to $2,800 to do so. The settlement: On June 15, 2018, the enforcement action brought by the FTC led to a shutdown of the website and permanently prohibited the defendants from posting intimate photos and personal information of other individuals without their consent. The defendants were also ordered to pay more than $2 million.3 Lenovo and Vizio The scenario: In 2018, FTC enforcement actions led to large settlements with technology manufacturers Lenovo and Vizio. The Lenovo settlement related to allegations the company sold computers in the U.S. with pre-installed software that sent consumer information to third parties without the knowledge of the users. With the New Jersey Office of Attorney General, the FTC also brought an enforcement action against Vizio, a manufacturer of \"smart\" televisions. Vizio entered into a settlement to resolve allegations it installed software on its televisions to collect consumer data without the knowledge or consent of consumers and sold the data to third parties. The settlement: Lenovo entered into a consent agreement to resolve the allegations through a decision and order issued by the FTC. The company was ordered to obtain affirmative consent from consumers before running the software on their computers and implement a software security program on preloaded software for the next 20 years.4 Vizio agreed to pay $2.2 million, delete the collected data, disclose all data collection and sharing practices, obtain express consent from consumers to collect or share their data, and implement a data security program.5 VTech The scenario: The FTC's action against toy manufacturer VTech was the first time the FTC became involved in a children's privacy and security matter. The settlement: In January 2018, the company entered into a settlement to pay $650,000 to resolve allegations it collected personal information from children without obtaining parental consent, in violation of COPPA. VTech was also required to implement a data security program that is subject to audits for the next 20 years.6 LabMD The scenario: LabMD, a cancer-screening company, was accused by the FTC of failing to reasonably protect consumers' medical information and other personal data. Identity thieves allegedly obtained sensitive data on LabMD consumers due to the company's failure to properly safeguard it. The billing information of 9,000 consumers was also compromised. The settlement: After years of litigation, the case was heard before the U.S. Court of Appeals for the Eleventh Circuit. LabMD argued, in part, that data security falls outside of the FTC's mandate over unfair practices. The Eleventh Circuit issued a decision in June 2018 that, while not stripping the FTC of authority to police data security, did challenge the remedy imposed by the FTC.7 The court ruled that the cease-and-desist order issued by the FTC against LabMD was unenforceable because the order required the company to implement a data security program that needed to adhere to a standard of \"reasonableness\" that was too vague.8 The ruling points to the need for the FTC to provide greater specificity in its cease-and-desist orders about what is required by companies that allegedly fail to safeguard consumer data. Footnotes 1 15 U.S.C. § 45(a)(1) 2 www.ftc.gov/news-events/press-releases/2018/04/uber-agrees-expanded-settlement-ftc-related-privacy-security 3 www.ftc.gov/system/files/documents/cases/emp_order_granting_default_judgment_6-22-18.pdf 4 www.ftc.gov/news-events/press-releases/2018/01/ftc-gives-final-approval-lenovo-settlement 5 www.ftc.gov/news-events/press-releases/2017/02/vizio-pay-22-million-ftc-state-newjersey-settle-charges-it 6 www.ftc.gov/news-events/press-releases/2018/01/electronic-toy-maker-vtech-settlesftc-allegations-it-violated 7 The United States Court of Appeals for the Third Circuit has rejected this argument. See FTC v. Wyndham Worldwide Corp., 799 F.3d 236, 247-49 (2015). 8 www.media.ca11.uscourts.gov/opinions/pub/files/201616270.pdf The content of this article is intended to provide a general guide to the subject matter. Specialist advice should be sought about your specific circumstances. Authors Marcia M. Ernst Your Author LinkedIn Connections RELATED ARTICLES Article Data Anonymization: Balancing Privacy And Usability United States Privacy ML Marcum Article Michigan AG Seeking More Consumer Protections Against Data Breaches, Price Gouging United States Privacy CO Cozen O'Connor Article Colorado And California Get Ahead Of Neural Data Regulation United States Privacy B BakerHostetler Article How ISO 27001 Supports Consumer Privacy: Part 2 United States Privacy DB Dunlap Bennett & Ludwig Read More About Privacy Privacy Protection Consumer Protection Consumer Law Technology Security Start a Guide Related Country Guides DP Data Privacy Related Webinars See More Webinar 19 Nov 2024 | 12:00 PM Digital Footprint – Your Success Factor Worldwide LL LINDEMANNLAW Webinar 21 Nov 2024 | 9:30 AM Surviving the Labour Code Minefield: The Critical Employer Hotspots Worldwide AP AZB & Partners Webinar Recorded on 19 Sep 2024 | 1:00 PM One Year On: Mastering Compliance with Switzerland's Data Protection Act Worldwide FP FABIAN PRIVACY LEGAL GmbH Upcoming Events Webinar 23 Oct 2024 Best Practices In Cyber Preparedness With Wiley & FTI Consulting United States Government WR Wiley Rein Webinar 24 Oct 2024 Data Privacy As Data Security: Recent Developments In US Data Regulation United States Privacy MB Mayer Brown Forum 24 Oct 2024 Privacy + Security Forum Fall Academy 2024 United States Consumer W WilmerHale See More Popular Content From Privacy Contributor United States Article Data Anonymization: Balancing Privacy And Usability United States Privacy ML Marcum Article Michigan AG Seeking More Consumer Protections Against Data Breaches, Price Gouging United States Privacy CO Cozen O'Connor Article Colorado And California Get Ahead Of Neural Data Regulation United States Privacy B BakerHostetler Article How ISO 27001 Supports Consumer Privacy: Part 2 United States Privacy DB Dunlap Bennett & Ludwig Article The Manufacturer's Guide To Building Brand Loyalty And Trust United States Privacy MG Macias Gini & O'Connell Article How ISO 27001 Supports Consumer Privacy: Part 1 United States Privacy DB Dunlap Bennett & Ludwig Article Deeper Dive: Preserving Ephemeral Messaging – Capture Data Before Its Ghosts Haunt Your Compliance United States Privacy B BakerHostetler Article Ransomware Claims Spike: Key Insights From Coalition's 2024 Cyber Claims Report United States Privacy BI Buchanan Ingersoll & Rooney PC Article Three Data Privacy Lessons Learned From The Marriott Data Breach United States Privacy GR Gray Reed & McGraw LLP Article U.S. Department Of Labor's Updated Cybersecurity Guidance For ERISA Plans United States Privacy RB Reinhart Boerner Van Deuren s.c. Connecting Knowledge & People Mondaq Tools Advice Centres Comparative Guides Newsletters Company About Mondaq Awards Blog Contact Us Legal Terms & Conditions Your Privacy Unsubscribe POWERED BY MONDAQ AI © Mondaq® Ltd 1994 - 2024. All Rights Reserved Mondaq uses cookies on this website. By using our website you agree to our use of cookies as set out in our Privacy Policy. Learn More Accept",
        "summary": "[[Summary: \n\n**Article Title:** Case Studies: High-Profile Cases of Privacy Violation  \n**Author:** SG Smith, Gambrell & Russell  \n**Date:** March 2019  \n\n**Key Cases Discussed:**\n\n1. **Uber Technologies**  \n   - **Scenario:** In August 2018, the FTC announced an expanded settlement with Uber for not securing sensitive data in the cloud, leading to a data breach.  \n   - **Data Compromised:** \n     - 600,000 names and driver's license numbers\n     - 22 million names and phone numbers\n     - Over 25 million names and email addresses  \n   - **Settlement Terms:** Uber must disclose future data breaches, submit reports for third-party audits of its privacy policy, and retain reports on unauthorized access to consumer data.\n\n2. **Emp Media Inc. (Myex.com)**  \n   - **Scenario:** The FTC and the State of Nevada acted against the \"revenge\" pornography website Myex.com, which posted intimate photos and personal information without consent.  \n   - **Settlement:** On June 15, 2018, the website was shut down, and the defendants were permanently prohibited from similar actions and ordered to pay over $2 million.\n\n3. **Lenovo and Vizio**  \n   - **Scenario:** In 2018, the FTC took action against Lenovo for pre-installed software that sent consumer information to third parties without user knowledge, and against Vizio for similar issues with its smart televisions.  \n   - **Lenovo Settlement:** Required to obtain consumer consent before running software and implement a security program for 20 years.  \n   - **Vizio Settlement:** Agreed to pay $2.2 million, delete collected data, disclose data practices, obtain express consent for data collection, and implement a data security program.\n\n4. **VTech**  \n   - **Scenario:** The FTC's first action regarding children's privacy involved VTech, which collected personal information from children without parental consent.  \n   - **Settlement:** VTech paid $650,000 and was required to implement a data security program subject to audits for 20 years.\n\n5. **LabMD**  \n   - **Scenario:** LabMD was accused of failing to protect consumer medical information, leading to identity theft and compromised billing information of 9,000 consumers.  \n   - **Settlement Outcome:** The U.S. Court of Appeals for the Eleventh Circuit ruled that the FTC's cease-and-desist order against LabMD was unenforceable due to vagueness regarding the standard of \"reasonableness\" for data security, indicating a need for clearer FTC guidelines.\n\n**Legal References:**  \n- 15 U.S.C. § 45(a)(1)  \n- Various FTC press releases and court rulings cited for detailed information on settlements and enforcement actions.\n\n**Additional Notes:**  \nThe article serves as a general guide to privacy violations and enforcement actions by the FTC, emphasizing the importance of data security and consumer protection. Specialist advice is recommended for specific circumstances.  \n]]",
        "url": "https://www.mondaq.com/unitedstates/privacy-protection/785230/case-studies-high-profile-cases-of-privacy-violation",
        "access_time": "2024-10-26T14:22:28.506143"
    },
    {
        "original_html": "You have reached the cached page for https://www.aclu.org/news/privacy-technology/supreme-courts-most-consequential-ruling-privacy-digitalBelow is a snapshot of the Web page as it appeared on 2024/10/26 (the last time our crawler visited it). This is the version of the page that was used for ranking your search results. The page may have changed since we last cached it. To see what might have changed (without the highlights), go to the current page.Bing is not responsible for the content of this page. Skip navigation Back to News & Commentary The Supreme Court’s Most Consequential Ruling for Privacy in the Digital Age, One Year In Nathan Freed Wessler, Deputy Director, ACLU Speech, Privacy, and Technology Project Share This Page June 28, 2019 This month marks a year since the Supreme Court issued its landmark privacy decision in Carpenter v. United States, ruling that the government must get a warrant before accessing a person’s sensitive cellphone location data. Carpenter, which the ACLU argued before the Supreme Court, concerned information revealing where Timothy Carpenter had traveled with his phone. The police, searching for evidence to connect Carpenter to the scenes of various robberies, obtained months’ worth of Carpenter’s detailed location data from his cellphone company without a warrant. That data exposed Carpenter’s daily routines, including where he slept and attended church. The court held that government access to such detailed location data provides a method of “near-perfect surveillance,” and recognized that the Fourth Amendment must protect such sensitive information. It added that old-world legal rules don’t automatically apply in the digital age. The Supreme Court’s decision stands as one of the most consequential rulings regarding privacy in the digital age, providing a roadmap for lower courts to protect many other kinds of sensitive data from warrantless government intrusion. One year in, we’re working to ensure that lower courts heed the high court’s call and extend the lessons of Carpenter to other contexts. For instance, we were in the Georgia Supreme Court last week arguing that Carpenter made clear courts cannot “mechanically apply” older legal doctrines that allow warrantless searches to new, complex digital-age contexts. Instead, courts should carefully assess what protections are necessary in light of rapidly advancing technology and increasingly accessible data. In that case, the state of Georgia is arguing that a legal doctrine dating back to the early 20th century should give police the authority to obtain — without a warrant — the vast and detailed data modern cars collect on us. This data can include everything from our car’s speed and braking data, to call record and text history, to music preferences and GPS coordinates. Under the dated doctrine, known as the “vehicle exemption,” police do not need a warrant to search a car for physical items due to the “ready mobility of vehicles,” which might drive away before a warrant is obtained. But, as we argued in court last week, that old rule shouldn’t be extended to override people’s unprecedented privacy interest in new kinds of sensitive digital data. Similarly, in our lawsuit challenging the government’s warrantless searches of electronic devices at the U.S. border, the federal government has been invoking a centuries-old rule allowing border agents to search travelers’ physical luggage without individualized suspicion or a warrant for contraband or import violations. We argue that old-world rules can’t be twisted into unfettered authority to search the incredible volumes of data on people’s phones and laptops when they return from a trip abroad. In both cases, Carpenter (and a predecessor Supreme Court case, Riley v. California) provide a powerful rebuke to the government’s arguments. The quantities and types of information that might be discovered by a manual search of a car’s trunk and glove compartment — or a traveler’s luggage — pale in comparison to the kinds of comprehensive data stored on our electronic devices today. This requires greater protections under the Fourth Amendment. Carpenter also holds that, in the digital age, our sensitive information does not lose Fourth Amendment protections merely because we store that information on a “third party” server, such as with Google or DropBox. This is a game-changer. In the digital age, it is virtually impossible to avoid leaving a trail of highly sensitive data. Our information is saved not only on our personal laptops and phones, but also on the servers of the companies with which we interact. As we argued in a case now before the First Circuit Court of Appeals, the government can no longer get away with warrantless searches of our personal information by relying on the “third party” doctrine. That case concerns the Drug Enforcement Administration’s efforts to access — without a warrant — people’s prescription records stored in the New Hampshire Prescription Drug Monitoring Program, a secure state-run database set up for public health purposes. The DEA is arguing that when people reveal their symptoms to their doctor and bring the doctor’s prescription to their pharmacist, they have given up their Fourth Amendment privacy rights in that sensitive health information. That can’t be right when the result is unfettered police access to deeply private information about our health and medical history. In other cases, we have similarly argued that people’s location history stored in gargantuan automated license plate reader databases should be protected by a warrant requirement because of the intense privacy interest in digitized location data recognized in Carpenter. The Supreme Court rightfully understood in Carpenter that courts have an essential role in ensuring that privacy protections remain vital in the digital age. While the government advocates for unfettered access to the personal information companies are sweeping up on us, it’s crucial the courts make clear, as Carpenter does, that we do not forfeit our Fourth Amendment rights simply for owning a laptop, driving a car, or having a cellphone. Learn More About the Issues on This Page Privacy & Technology Cell Phone Privacy Location Tracking Related Content News & Commentary News & Commentary DHS Focus on \"Soft Targets\" Risks Out-of-Control Surveillance Press Release Press Release ACLU Warns that Biden-Harris Administration Rules on AI in National Security Lack Key Protections News & Commentary News & Commentary State Legislatures Need to Block Creation of Nightmarish National Identity System Press Release Press Release Child Safety, Free Speech, and Privacy Experts Tell Supreme Court: Texas’s Unconstitutional Age Verification Law Must be Overturned",
        "summary": "[[Summary: \n\n1. **Title**: The Supreme Court’s Most Consequential Ruling for Privacy in the Digital Age, One Year In\n2. **Author**: Nathan Freed Wessler, Deputy Director, ACLU Speech, Privacy, and Technology Project\n3. **Date**: June 28, 2019\n4. **Key Case**: Carpenter v. United States\n   - **Significance**: Landmark decision requiring law enforcement to obtain a warrant to access sensitive cellphone location data.\n   - **Context**: The case involved Timothy Carpenter, whose detailed location data was obtained by police without a warrant during investigations of robberies.\n   - **Ruling**: The Supreme Court recognized that such data allows for \"near-perfect surveillance\" and emphasized the need for Fourth Amendment protections in the digital age.\n5. **Implications**: \n   - The decision serves as a roadmap for lower courts to protect various types of sensitive data from warrantless searches.\n   - The ACLU is advocating for the application of Carpenter's principles in other legal contexts, such as:\n     - **Georgia Supreme Court Case**: Challenging the use of an early 20th-century legal doctrine (vehicle exemption) that allows police to access detailed data from modern vehicles without a warrant.\n     - **Electronic Device Searches at U.S. Borders**: Contesting the government's claim that old rules allow warrantless searches of digital data on travelers' devices.\n6. **Related Legal Precedent**: Riley v. California, which also addresses the need for greater protections for digital data.\n7. **Third-Party Doctrine**: The ruling asserts that sensitive information stored on third-party servers (e.g., Google, Dropbox) retains Fourth Amendment protections, challenging the government's ability to conduct warrantless searches based on this doctrine.\n8. **Current Legal Challenges**:\n   - ACLU is involved in a case regarding the DEA's warrantless access to prescription records in New Hampshire.\n   - Advocating for warrant requirements for location data from automated license plate readers.\n9. **Conclusion**: The Supreme Court's decision in Carpenter is seen as a critical affirmation of privacy rights in the digital age, emphasizing that individuals retain their Fourth Amendment rights regardless of the technology they use.\n\n]]",
        "url": "https://www.aclu.org/news/privacy-technology/supreme-courts-most-consequential-ruling-privacy-digital",
        "access_time": "2024-10-26T14:22:28.548256"
    },
    {
        "original_html": "You have reached the cached page for https://www.sgrlaw.com/ttl-articles/case-studies-high-profile-cases-of-privacy-violation/Below is a snapshot of the Web page as it appeared on 2024/10/26 (the last time our crawler visited it). This is the version of the page that was used for ranking your search results. The page may have changed since we last cached it. To see what might have changed (without the highlights), go to the current page.Bing is not responsible for the content of this page. Menu Experience Industries Services Professionals Resources SGR Insights News & Events Client Access About The Firm Careers Contact SGR Alumni Share Home Publications Issue 45/Winter 2019 Case Studies: High-Profile Cases of Privacy Violation Case Studies: High-Profile Cases of Privacy Violation Case Studies: Recent FTC Enforcement Actions - High-Profile Cases of Privacy Violation: Uber, Emp Media, Lenovo, Vizio, VTech, LabMD Uber Technologies The scenario: In August 2018, the FTC announced an expanded settlement with Uber Technologies for its alleged failure to reasonably secure sensitive data in the cloud, resulting in a data breach of 600,000 names and driver’s license numbers, 22 million names and phone numbers, and more than 25 million names and email addresses. The settlement: The expanded settlement is a result of Uber’s failure to disclose a significant data breach that occurred in 2016 while the FTC was conducting its investigation that led to the original settlement. The revised proposed order includes provisions requiring Uber to disclose any future consumer data breaches, submit all reports for third-party audits of Uber’s privacy policy and retain reports on unauthorized access to consumer data.2 Emp Media Inc. (Myex.com) The scenario: The FTC joined forces with the State of Nevada to address privacy issues arising from the “revenge” pornography website, Myex.com, run by Emp Media Inc. The website allowed individuals to submit intimate photos of the victims, including personal information such as name, address, phone number and social media accounts. If a victim wanted their photos and information removed from the website, the defendants reportedly charged fees of $499 to $2,800 to do so. The settlement: On June 15, 2018, the enforcement action brought by the FTC led to a shutdown of the website and permanently prohibited the defendants from posting intimate photos and personal information of other individuals without their consent. The defendants were also ordered to pay more than $2 million.3 Lenovo and Vizio The scenario: In 2018, FTC enforcement actions led to large settlements with technology manufacturers Lenovo and Vizio. The Lenovo settlement related to allegations the company sold computers in the U.S. with pre-installed software that sent consumer information to third parties without the knowledge of the users. With the New Jersey Office of Attorney General, the FTC also brought an enforcement action against Vizio, a manufacturer of “smart” televisions. Vizio entered into a settlement to resolve allegations it installed software on its televisions to collect consumer data without the knowledge or consent of consumers and sold the data to third parties. The settlement: Lenovo entered into a consent agreement to resolve the allegations through a decision and order issued by the FTC. The company was ordered to obtain affirmative consent from consumers before running the software on their computers and implement a software security program on preloaded software for the next 20 years.4 Vizio agreed to pay $2.2 million, delete the collected data, disclose all data collection and sharing practices, obtain express consent from consumers to collect or share their data, and implement a data security program.5 VTech The scenario: The FTC’s action against toy manufacturer VTech was the first time the FTC became involved in a children’s privacy and security matter. The settlement: In January 2018, the company entered into a settlement to pay $650,000 to resolve allegations it collected personal information from children without obtaining parental consent, in violation of COPPA. VTech was also required to implement a data security program that is subject to audits for the next 20 years.6 LabMD The scenario: LabMD, a cancer-screening company, was accused by the FTC of failing to reasonably protect consumers’ medical information and other personal data. Identity thieves allegedly obtained sensitive data on LabMD consumers due to the company’s failure to properly safeguard it. The billing information of 9,000 consumers was also compromised. The settlement: After years of litigation, the case was heard before the U.S. Court of Appeals for the Eleventh Circuit. LabMD argued, in part, that data security falls outside of the FTC’s mandate over unfair practices. The Eleventh Circuit issued a decision in June 2018 that, while not stripping the FTC of authority to police data security, did challenge the remedy imposed by the FTC.7 The court ruled that the cease-and-desist order issued by the FTC against LabMD was unenforceable because the order required the company to implement a data security program that needed to adhere to a standard of “reasonableness” that was too vague.8 The ruling points to the need for the FTC to provide greater specificity in its cease-and-desist orders about what is required by companies that allegedly fail to safeguard consumer data. Endnotes 15 U.S.C. § 45(a)(1) www.ftc.gov/news-events/press-releases/2018/04/uber-agrees-expanded-settlement-ftc-related-privacy-security www.ftc.gov/system/files/documents/cases/emp_order_granting_default_judgment_6-22-18.pdf www.ftc.gov/news-events/press-releases/2018/01/ftc-gives-final-approval-lenovo-settlement www.ftc.gov/news-events/press-releases/2017/02/vizio-pay-22-million-ftc-state-newjersey-settle-charges-it www.ftc.gov/news-events/press-releases/2018/01/electronic-toy-maker-vtech-settlesftc-allegations-it-violated The United States Court of Appeals for the Third Circuit has rejected this argument. See FTC v. Wyndham Worldwide Corp., 799 F.3d 236, 247-49 (2015). www.media.ca11.uscourts.gov/opinions/pub/files/201616270.pdf Browse Back Issues Trust the Leaders 2.0 Volume 7 Trust the Leaders 2.0 Volume 6 Trust the Leaders 2.0 Volume 5 TTL 2.0 Volume 4 Issue 47 Issue 46/Summer 2019 Issue 45/Winter 2019 Issue 44/Summer 2018 Issue 43/Winter 2018 Issue 42/Summer 2017 Issue 41/Winter 2017 Issue 40/ Summer 2016 Issue 39 / Winter 2016 Issue 38 / Summer 2015 Issue 37 / Winter 2015 Issue 36 / Summer 2014 Issue 35 / Winter 2014 Issue 34 / Summer 2013 Issue 33 / Winter 2013 Issue 32 / Summer 2012 Issue 31 / Winter 2011 Issue 30 / Fall 2011 Issue 29 / Summer 2011 Issue 28 / Winter 2010/2011 Issue 27 / Summer 2010 Issue 26 / Spring 2010 Issue 25 / Winter 2009/2010 Issue 24 / Summer 2009 Issue 23 / Spring 2009 Issue 22 / Summer 2008 Issue 21 / Spring 2008 Issue 20 / Fall 2007 Issue 19 / Summer 2007 Issue 18 / Spring 2007 Issue 17 / Winter 2006 Issue 16 / Summer 2006 Issue 15 / Spring 2006 Issue 14 / Winter 2005 Issue 13 / Fall 2005 Issue 12 / Summer 2005 Issue 11 / Spring 2005 Issue 10 / Winter 2004 Issue 9 / Fall 2004 Issue 8 / Summer 2004 Issue 7 / Spring 2004 Issue 6 / Winter 2003 Issue 5 / Fall 2003 Issue 4 / Summer 2003 Issue 3 / Spring 2003 Issue 2 / Winter 2002 Issue 1 / Fall 2002 Authored By Ernst, Marcia Smith, Gambrell & Russell, LLP SGRLAW® Experience Industries Services Professionals Resources SGR Insights News & Events Client Access About The Firm Careers Contact SGR Alumni Notices Site Terms Privacy Policy Cookies Policy SGR Int’l Transparency In Coverage Rule Languages Español Deutsch 한국어 日本語 中文 Search Remote Access © 2024 Smith, Gambrell & Russell, LLP Facebook Twitter LinkedIn More Networks Share via Facebook X (Twitter) LinkedIn Mix Email Print Copy Link Powered by Social Snap Copy link CopyCopied Powered by Social Snap This website uses cookies to improve functionality and performance. If you continue browsing the site, you are giving implied consent to the use of cookies on this website.OkNo",
        "summary": "[[Summary: \n\n**Title:** Case Studies: High-Profile Cases of Privacy Violation\n\n**Main Topics:**\n1. **FTC Enforcement Actions**: Overview of various high-profile privacy violation cases involving companies like Uber, Emp Media, Lenovo, Vizio, VTech, and LabMD.\n\n**Key Cases:**\n\n1. **Uber Technologies**:\n   - **Scenario**: In August 2018, the FTC announced an expanded settlement due to Uber's inadequate security measures that led to a data breach affecting 600,000 names and driver’s license numbers, 22 million names and phone numbers, and over 25 million names and email addresses.\n   - **Settlement**: Uber must disclose future data breaches, submit to third-party audits of its privacy policy, and retain reports on unauthorized access to consumer data.\n\n2. **Emp Media Inc. (Myex.com)**:\n   - **Scenario**: The FTC, in collaboration with the State of Nevada, targeted the revenge pornography website Myex.com, which allowed users to post intimate photos without consent, charging victims $499 to $2,800 to remove their content.\n   - **Settlement**: On June 15, 2018, the site was shut down, and the defendants were permanently prohibited from posting such content and ordered to pay over $2 million.\n\n3. **Lenovo and Vizio**:\n   - **Lenovo**: Allegedly sold computers with pre-installed software that transmitted consumer data without users' knowledge. The settlement required Lenovo to obtain consumer consent before running such software and to implement a security program for 20 years.\n   - **Vizio**: Accused of collecting consumer data from smart TVs without consent. The settlement involved a $2.2 million payment, deletion of collected data, and a commitment to transparency regarding data collection practices.\n\n4. **VTech**:\n   - **Scenario**: The FTC's first action concerning children's privacy, as VTech collected personal information from children without parental consent, violating COPPA.\n   - **Settlement**: In January 2018, VTech agreed to pay $650,000 and implement a data security program subject to audits for 20 years.\n\n5. **LabMD**:\n   - **Scenario**: Accused by the FTC of failing to protect sensitive consumer medical information, resulting in identity theft. The case was litigated for years, culminating in a ruling by the U.S. Court of Appeals for the Eleventh Circuit.\n   - **Settlement**: The court ruled that the FTC’s cease-and-desist order was unenforceable due to vague standards for data security, highlighting the need for clearer guidelines from the FTC.\n\n**Important Dates**:\n- August 2018: FTC expanded settlement with Uber.\n- June 15, 2018: FTC enforcement action against Emp Media.\n- January 2018: Settlement with VTech.\n- June 2018: Eleventh Circuit ruling on LabMD case.\n\n**Key Insights**:\n- The cases illustrate the FTC's increasing focus on data security and privacy, particularly regarding consumer consent and protection of sensitive information.\n- The rulings and settlements underscore the necessity for companies to adopt robust data protection practices and the FTC's role in enforcing privacy regulations.\n\n**Endnotes**: References to legal documents and specific FTC press releases related to each case.\n\n]]",
        "url": "https://www.sgrlaw.com/ttl-articles/case-studies-high-profile-cases-of-privacy-violation/",
        "access_time": "2024-10-26T14:22:27.304272"
    }
]